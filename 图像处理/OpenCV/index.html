<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
<meta name="referrer" content="no-referrer">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yanglinqi107.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="OpenCV官网：https:&#x2F;&#x2F;opencv.org&#x2F;  ， 中文官网：https:&#x2F;&#x2F;www.opencv.org.cn OpenCV中文网站-论坛 - Powered by Discuz!   官方文档：OpenCV documentation index https:&#x2F;&#x2F;opencv.apachecn.org&#x2F;#&#x2F; OpenCV是应用广泛的开源图像处理库，我们以其为基础，介绍相关的图像处理">
<meta property="og:type" content="article">
<meta property="og:title" content="OpenCV入门(Python)">
<meta property="og:url" content="http://yanglinqi107.github.io/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/OpenCV/index.html">
<meta property="og:site_name" content="杨记">
<meta property="og:description" content="OpenCV官网：https:&#x2F;&#x2F;opencv.org&#x2F;  ， 中文官网：https:&#x2F;&#x2F;www.opencv.org.cn OpenCV中文网站-论坛 - Powered by Discuz!   官方文档：OpenCV documentation index https:&#x2F;&#x2F;opencv.apachecn.org&#x2F;#&#x2F; OpenCV是应用广泛的开源图像处理库，我们以其为基础，介绍相关的图像处理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image1.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-24_11-19-33.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-24_11-19-57.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-24_11-46-55.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-24_14-12-27.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-23_16-42-18.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190925154009533.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191016154526370.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191016154714377.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191016161128720.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926143500645.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926151127550.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023102648731.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023102927643.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023103038145.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023103106568.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023105453003.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926152854704.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023115222617.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926161027173.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023130051717.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926162913916.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/timg.jpeg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20230226174240926.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926185646667.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926185504256.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927101630929.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927105316401.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927110711458.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927151844574.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927142206425.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927142923777.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927153400823.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927154018177.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927163654718.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927164749878.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927164045611.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928102258185.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928104118332.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110341406.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110425845.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110455467.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110522272.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110551897.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110613880.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928111903926.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928102319410.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928144352467.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928145730979.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928155000064.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928160241831.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928162111755.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928163431354.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191024105039014.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191024105353109.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928165605432.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191024160953045.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929104240226.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929104430480.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929141752847.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929141636521.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929145507862.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929153926063.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929155208751.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929160959357.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191024180930270.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Template_Matching_Template_Theory_Summary.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Template_Matching_Template_Theory_Sliding.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Template_Matching_Template_Theory_Result.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/wulin2.jpeg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/wulin-0430810.jpeg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007144614688.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007151122386.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007153126537.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007154123721.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007154350195.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007154546905.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007160434136.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007160932077.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007161219204.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007161417485.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007165431682.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007163203594.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007170330026.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image70-0440438.gif">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007184838549.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/rili.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007184301611.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008105125382.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008141826875.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008141945745.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008144647540.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008153014984.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191015180016665.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008160908338.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008161040473.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008161904372.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008164344988.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008171309192.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008174257711-167759358741034.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008181535222-167759455781036.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009110944907-167759498591538.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009113953721-167759506125740.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009115023016-167759558757842.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009143818527-167759743395844.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009144726492-167759745931346.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009150008701-167759749637048.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191025112522974-167759754642250.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009161647267-167759767449452.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009161756423-167759774753954.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009162914982-167759777357556.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009181525538.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image17.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010114459269.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010120822413.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010145652681.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010153907973.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010161944491.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010162532196.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image1-0784863-16777246863615.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image2-0785334-16777247135957.gif">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191011180244485-16777247467209.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image4-167772478479211.gif">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014152218924-167772525674113.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014152716626-167772527072915.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014160504382-167772528427717.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014160719733-167772532593419.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014164455020-167772535167121.png">
<meta property="article:published_time" content="2023-03-03T06:47:53.686Z">
<meta property="article:modified_time" content="2023-08-06T06:37:44.643Z">
<meta property="article:author" content="yanglinqi">
<meta property="article:tag" content="图像处理">
<meta property="article:tag" content="OpenCV">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image1.jpg">

<link rel="canonical" href="http://yanglinqi107.github.io/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/OpenCV/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>OpenCV入门(Python) | 杨记</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">杨记</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">碎片化学习令人焦虑，系统化学习使人进步</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">28</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">18</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">98</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yanglinqi107.github.io/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/OpenCV/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headpic.jpg">
      <meta itemprop="name" content="yanglinqi">
      <meta itemprop="description" content="用于做笔记，对学过的知识总结">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="杨记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          OpenCV入门(Python)
        </h1>

        <div class="post-meta">

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-03-03 14:47:53" itemprop="dateCreated datePublished" datetime="2023-03-03T14:47:53+08:00">2023-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-06 14:37:44" itemprop="dateModified" datetime="2023-08-06T14:37:44+08:00">2023-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">图像处理</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>OpenCV官网：<a target="_blank" rel="noopener" href="https://opencv.org/">https://opencv.org/</a>  ， 中文官网：<a target="_blank" rel="noopener" href="https://www.opencv.org.cn/">https://www.opencv.org.cn</a></p>
<p><a target="_blank" rel="noopener" href="https://www.opencv.org.cn/forum/">OpenCV中文网站-论坛 - Powered by Discuz!</a>   官方文档：<a target="_blank" rel="noopener" href="https://docs.opencv.org/">OpenCV documentation index</a></p>
<p><a target="_blank" rel="noopener" href="https://opencv.apachecn.org/#/">https://opencv.apachecn.org/#/</a></p>
<p>OpenCV是应用广泛的开源图像处理库，我们以其为基础，介绍相关的图像处理方法：包括基本的图像处理方法：几何变换，形态学变换，图像平滑，直方图操作，模板匹配，霍夫变换等；特征提取和描述方法：理解角点特征，Harris和Shi-Tomas算法，SIFT/SURF算法，Fast算法，ORB算法等；还有OpenCV在视频操作中的应用，最后的案例是使用OpenCV进行人脸检测。</p>
<p>？m连通</p>
<span id="more"></span>
<h2 id="OpenCV简介"><a href="#OpenCV简介" class="headerlink" title="OpenCV简介"></a>OpenCV简介</h2><ul>
<li>图像的起源和数字图像</li>
<li>OpenCV的简介及其部署方法</li>
<li>OpenCV中包含的主要模块。</li>
</ul>
<h3 id="图像处理简介"><a href="#图像处理简介" class="headerlink" title="图像处理简介"></a>图像处理简介</h3><h4 id="图像是什么"><a href="#图像是什么" class="headerlink" title="图像是什么"></a>图像是什么</h4><blockquote>
<p>图像是人类视觉的基础，是自然景物的客观反映，是人类认识世界和人类本身的重要源泉。“图”是物体反射或透射光的分布，“像“是人的视觉系统所接受的图在人脑中所形版的印象或认识，照片、绘画、剪贴画、地图、书法作品、手写汉学、传真、卫星云图、影视画面、X光片、脑电图、心电图等都是图像。——姚敏. 数字图像处理：机械工业出版社，2014年。</p>
</blockquote>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image1.jpg" alt="image1" style="zoom: 33%;" /></p>
<h4 id="模拟图像和数字图像"><a href="#模拟图像和数字图像" class="headerlink" title="模拟图像和数字图像"></a>模拟图像和数字图像</h4><p>图像起源于1826年前后法国科学家Joseph Nicéphore Niépce发明的第一张可永久保存的照片，属于模拟图像。模拟图像又称连续图像，它通过某种物理量（如光、电等）的强弱变化来记录图像亮度信息，所以是连续变换的。模拟信号的特点是容易受干扰，如今已经基本全面被数字图像替代。</p>
<p>在第一次世界大战后，1921年美国科学家发明了Bartlane System，并从伦敦传到纽约传输了第一幅数字图像，其亮度用离散数值表示，将图片编码成5个灰度级，如下图所示，通过海底电缆进行传输。在发送端图片被编码并使用打孔带记录，通过系统传输后在接收方使用特殊的打印机恢复成图像。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-24_11-19-33.png" alt="Snipaste_2019-09-24_11-19-33" style="zoom: 67%;" /></p>
<p>1950年左右，计算机被发明，数字图像处理学科正式诞生。</p>
<p>模拟图像和数字图像的对比，我们可以看一下：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-24_11-19-57.png" alt="Snipaste_2019-09-24_11-19-57" style="zoom: 67%;" /></p>
<h4 id="数字图像的表示"><a href="#数字图像的表示" class="headerlink" title="数字图像的表示"></a>数字图像的表示</h4><h5 id="位数"><a href="#位数" class="headerlink" title="位数"></a>位数</h5><p>计算机采用0/1编码的系统，数字图像也是利用0/1来记录信息，我们平常接触的图像都是8位数图像，包含0～255灰度，其中0，代表最黑，1，表示最白。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-24_11-46-55.png" alt="Snipaste_2019-09-24_11-46-55" style="zoom:50%;" /></p>
<p>人眼对灰度更敏感一些，在16位到32位之间。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-24_14-12-27.png" alt="Snipaste_2019-09-24_14-12-27" style="zoom: 33%;" /></p>
<h5 id="图像的分类"><a href="#图像的分类" class="headerlink" title="图像的分类"></a>图像的分类</h5><p><strong>二值图像</strong>：</p>
<p>一幅二值图像的二维矩阵仅由0、1两个值构成，“0”代表黑色，“1”代白色。由于每一像素（矩阵中每一元素）取值仅有0、1两种可能，所以计算机中二值图像的数据类型通常为1个二进制位。二值图像通常用于文字、线条图的扫描识别（OCR）和掩膜图像的存储。</p>
<p><strong>灰度图</strong>：</p>
<p>每个像素只有一个采样颜色的图像，这类图像通常显示为从最暗黑色到最亮的白色的灰度，尽管理论上这个采样可以任何颜色的不同深浅，甚至可以是不同亮度上的不同颜色。灰度图像与黑白图像不同，在计算机图像领域中黑白图像只有黑色与白色两种颜色；但是，灰度图像在黑色与白色之间还有许多级的颜色深度。灰度图像经常是在单个电磁波频谱如可见光内测量每个像素的亮度得到的，用于显示的灰度图像通常用每个采样像素8位的非线性尺度来保存，这样可以有256级灰度（如果用16位，则有65536级）。</p>
<p><strong>彩色图</strong>：</p>
<p>每个像素通常是由红（R）、绿（G）、蓝（B）三个分量来表示的，分量介于（0，255）。RGB图像与索引图像一样都可以用来表示彩色图像。与索引图像一样，它分别用红（R）、绿（G）、蓝（B）三原色的组合来表示每个像素的颜色。但与索引图像不同的是，RGB图像每一个像素的颜色值（由RGB三原色表示）直接存放在图像矩阵中，由于每一像素的颜色需由R、G、B三个分量来表示，M、N分别表示图像的行列数，三个M x N的二维矩阵分别表示各个像素的R、G、B三个颜色分量。RGB图像的数据类型一般为8位无符号整形，通常用于表示和存放真彩色图像。</p>
<h3 id="安装OpenCV"><a href="#安装OpenCV" class="headerlink" title="安装OpenCV"></a>安装OpenCV</h3><h4 id="OpenCV简介-1"><a href="#OpenCV简介-1" class="headerlink" title="OpenCV简介"></a>OpenCV简介</h4><p>OpenCV是一款由Intel公司俄罗斯团队发起并参与和维护的一个计算机视觉处理开源软件库，支持与计算机视觉和机器学习相关的众多算法，并且正在日益扩展。</p>
<p>OpenCV的优势：</p>
<ol>
<li>编程语言：OpenCV基于C++实现，同时提供python, Ruby, Matlab等语言的接口。OpenCV-Python是OpenCV的Python API，结合了OpenCV C++ API和Python语言的最佳特性。</li>
<li>跨平台：可以在不同的系统平台上使用，包括Windows，Linux，OS X，Android和iOS。基于CUDA和OpenCL的高速GPU操作接口也在积极开发中</li>
<li>活跃的开发团队</li>
<li>丰富的API：完善的传统计算机视觉算法，涵盖主流的机器学习算法，同时添加了对深度学习的支持。</li>
</ol>
<h4 id="OpenCV-Python"><a href="#OpenCV-Python" class="headerlink" title="OpenCV-Python"></a>OpenCV-Python</h4><p>OpenCV-Python是一个Python绑定库，旨在解决计算机视觉问题。</p>
<p>Python是一种由Guido van Rossum开发的通用编程语言，它很快就变得非常流行，主要是因为它的简单性和代码可读性。它使程序员能够用更少的代码行表达思想，而不会降低可读性。</p>
<p>与C / C++等语言相比，Python速度较慢。也就是说，Python可以使用C / C++轻松扩展，这使我们可以在C / C++中编写计算密集型代码，并创建可用作Python模块的Python包装器。这给我们带来了两个好处：首先，代码与原始C / C++代码一样快（因为它是在后台工作的实际C++代码），其次，在Python中编写代码比使用C / C++更容易。OpenCV-Python是原始OpenCV C++实现的Python包装器。</p>
<p>OpenCV-Python使用Numpy，这是一个高度优化的数据库操作库，具有MATLAB风格的语法。所有OpenCV数组结构都转换为Numpy数组。这也使得与使用Numpy的其他库（如SciPy和Matplotlib）集成更容易。</p>
<h4 id="OpenCV部署方法"><a href="#OpenCV部署方法" class="headerlink" title="OpenCV部署方法"></a>OpenCV部署方法</h4><p>安装OpenCV之前需要先安装numpy, matplotlib。</p>
<p>创建Python虚拟环境cv, 在cv中安装即可。</p>
<p>先安装OpenCV-Python, 由于一些经典的算法被申请了版权，新版本有很大的限制，所以选用3.4.3以下的版本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-python==3.4.2.17</span><br></pre></td></tr></table></figure>
<p>现在可以测试下是否安装成功，运行以下代码无报错则说明安装成功。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 读一个图片并进行显示(图片路径需自己指定)</span></span><br><span class="line">lena=cv2.imread(<span class="string">&quot;1.jpg&quot;</span>)</span><br><span class="line">cv2.imshow(<span class="string">&quot;image&quot;</span>,lena)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>如果我们要利用SIFT和SURF等进行特征提取时，还需要安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-contrib-python==3.4.2.17</span><br></pre></td></tr></table></figure>
<h3 id="OpenCV的模块"><a href="#OpenCV的模块" class="headerlink" title="OpenCV的模块"></a>OpenCV的模块</h3><p>下图列出了OpenCV中包含的各个模块：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Snipaste_2019-09-23_16-42-18.png" alt="Snipaste_2019-09-23_16-42-18" style="zoom: 67%;" /></p>
<p>其中core、highgui、imgproc是最基础的模块，该课程主要是围绕这几个模块展开的，分别介绍如下：</p>
<ul>
<li><strong>core模块</strong>实现了最核心的数据结构及其基本运算，如绘图函数、数组操作相关函数等。</li>
<li><strong>highgui模块</strong>实现了视频与图像的读取、显示、存储等接口。</li>
<li><strong>imgproc模块</strong>实现了图像处理的基础方法，包括图像滤波、图像的几何变换、平滑、阈值分割、形态学处理、边缘检测、目标检测、运动分析和对象跟踪等。</li>
</ul>
<p>对于图像处理其他更高层次的方向及应用，OpenCV也有相关的模块实现</p>
<ul>
<li><strong>features2d模块</strong>用于提取图像特征以及特征匹配，nonfree模块实现了一些专利算法，如sift特征。</li>
<li><strong>objdetect模块</strong>实现了一些目标检测的功能，经典的基于Haar、LBP特征的人脸检测，基于HOG的行人、汽车等目标检测，分类器使用Cascade Classification（级联分类）和Latent SVM等。</li>
<li><strong>stitching模块</strong>实现了图像拼接功能。</li>
<li><strong>FLANN模块</strong>（Fast Library for Approximate Nearest Neighbors），包含快速近似最近邻搜索FLANN 和聚类Clustering算法。</li>
<li><strong>ml模块</strong>机器学习模块（SVM，决策树，Boosting等等）。</li>
<li><strong>photo模块</strong>包含图像修复和图像去噪两部分。</li>
<li><strong>video模块</strong>针对视频处理，如背景分离，前景检测、对象跟踪等。</li>
<li><strong>calib3d模块</strong>即Calibration（校准）3D，这个模块主要是相机校准和三维重建相关的内容。包含了基本的多视角几何算法，单个立体摄像头标定，物体姿态估计，立体相似性算法，3D信息的重建等等。</li>
<li><strong>G-API模块</strong>包含超高效的图像处理pipeline引擎</li>
</ul>
<h2 id="OpenCV基本操作"><a href="#OpenCV基本操作" class="headerlink" title="OpenCV基本操作"></a>OpenCV基本操作</h2><ul>
<li>图像的IO操作，读取和保存方法</li>
<li>在图像上绘制几何图形</li>
<li>怎么获取图像的属性</li>
<li>怎么访问图像的像素，进行通道分离，合并等</li>
<li>怎么实现颜色空间的变换</li>
<li>图像的算术运算</li>
</ul>
<h3 id="图像的基础操作"><a href="#图像的基础操作" class="headerlink" title="图像的基础操作"></a>图像的基础操作</h3><h4 id="图像的IO操作"><a href="#图像的IO操作" class="headerlink" title="图像的IO操作"></a>图像的IO操作</h4><p><strong>1、读取图像</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.imread()	 <span class="comment"># 读取图像</span></span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li><p>要读取的图像</p>
</li>
<li><p>读取方式的标志</p>
<ul>
<li><p>cv.IMREAD*COLOR：以彩色模式加载图像，任何图像的透明度都将被忽略。这是默认参数。</p>
</li>
<li><p>cv.IMREAD*GRAYSCALE：以灰度模式加载图像</p>
</li>
<li><p>cv.IMREAD_UNCHANGED：包括alpha通道的加载图像模式。</p>
<p><strong>可以使用1、0或者-1来替代上面三个标志</strong></p>
</li>
</ul>
</li>
<li><p>参考代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="comment"># 以灰度图的形式读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;messi5.jpg&#x27;</span>,<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>注意：如果加载的路径有错误，不会报错，会返回一个None值</strong></p>
<p><strong>2、显示图像</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.imshow()  <span class="comment"># 显示图像</span></span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>显示图像的窗口名称，以字符串类型表示</li>
<li>要加载的图像</li>
</ul>
<p><strong>注意：在调用显示图像的API后，要调用cv.waitKey()给图像绘制留下时间，否则窗口会出现无响应情况，并且图像无法显示出来</strong>。</p>
<p>另外我们也可使用matplotlib对图像进行展示。</p>
<ol>
<li><p>参考代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># opencv中显示</span></span><br><span class="line">cv.imshow(<span class="string">&#x27;image&#x27;</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># matplotlib中展示</span></span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>])  <span class="comment"># rgb -&gt; bgr </span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>3、保存图像</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.imwrite()  <span class="comment"># 保存图像</span></span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>文件名，要保存在哪里</li>
<li>要保存的图像</li>
</ul>
<p>参考代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.imwrite(<span class="string">&#x27;messigray.png&#x27;</span>,img)</span><br></pre></td></tr></table></figure>
<p><strong>代码示例</strong></p>
<p>我们通过加载灰度图像，显示图像，如果按’s’并退出则保存图像，或者按ESC键直接退出而不保存。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;messi5.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 2 显示图像</span></span><br><span class="line"><span class="comment"># 2.1 利用opencv展示图像</span></span><br><span class="line">cv.imshow(<span class="string">&#x27;image&#x27;</span>,img)</span><br><span class="line"><span class="comment"># 2.2 在matplotplotlib中展示图像</span></span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;匹配结果&#x27;</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br><span class="line">k = cv.waitKey(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 3 保存图像</span></span><br><span class="line">cv.imwrite(<span class="string">&#x27;messigray.png&#x27;</span>,img)</span><br></pre></td></tr></table></figure>
<h4 id="绘制几何图形"><a href="#绘制几何图形" class="headerlink" title="绘制几何图形"></a>绘制几何图形</h4><p><strong>1、绘制直线</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.line(img,start,end,color,thickness)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>img:要绘制直线的图像</li>
<li>Start,end: 直线的起点和终点</li>
<li>color: 线条的颜色</li>
<li>Thickness: 线条宽度</li>
</ul>
<p><strong>2、绘制圆形</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.circle(img,centerpoint, r, color, thickness)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>img:要绘制圆形的图像</li>
<li>Centerpoint, r: 圆心和半径</li>
<li>color: 线条的颜色</li>
<li>Thickness: 线条宽度，为-1时生成闭合图案并填充颜色</li>
</ul>
<p><strong>3、绘制矩形</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.rectangle(img,leftupper,rightdown,color,thickness)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>img:要绘制矩形的图像</li>
<li>Leftupper, rightdown: 矩形的左上角和右下角坐标</li>
<li>color: 线条的颜色</li>
<li>Thickness: 线条宽度</li>
</ul>
<p><strong>4、向图像中添加文字</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.putText(img,text,station, font, fontsize,color,thickness,cv.LINE_AA)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>img: 图像</li>
<li>text：要写入的文本数据</li>
<li>station：文本的放置位置</li>
<li>font：字体</li>
<li>Fontsize :字体大小</li>
</ul>
<p><strong>代码示例</strong></p>
<p>我们生成一个全黑的图像，然后在里面绘制图像并添加文字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 创建一个空白的图像</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line"><span class="comment"># 2 绘制图形</span></span><br><span class="line">cv.line(img,(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">511</span>,<span class="number">511</span>),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">5</span>)</span><br><span class="line">cv.rectangle(img,(<span class="number">384</span>,<span class="number">0</span>),(<span class="number">510</span>,<span class="number">128</span>),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">3</span>)</span><br><span class="line">cv.circle(img,(<span class="number">447</span>,<span class="number">63</span>), <span class="number">63</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), -<span class="number">1</span>)</span><br><span class="line">font = cv.FONT_HERSHEY_SIMPLEX</span><br><span class="line">cv.putText(img,<span class="string">&#x27;OpenCV&#x27;</span>,(<span class="number">10</span>,<span class="number">500</span>), font, <span class="number">4</span>,(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>),<span class="number">2</span>,cv.LINE_AA)</span><br><span class="line"><span class="comment"># 3 图像展示</span></span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;匹配结果&#x27;</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190925154009533.png" alt="image-20190925154009533" style="zoom:50%;" /></p>
<h4 id="获取-修改像素点"><a href="#获取-修改像素点" class="headerlink" title="获取/修改像素点"></a>获取/修改像素点</h4><p>我们可以通过行和列的坐标值获取该像素点的像素值。对于BGR图像，它返回一个蓝，绿，红值的数组。对于灰度图像，仅返回相应的强度值。使用相同的方法对像素值进行修改。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">&#x27;messi5.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 获取某个像素点的值</span></span><br><span class="line">px = img[<span class="number">100</span>,<span class="number">100</span>]</span><br><span class="line"><span class="comment"># 仅获取蓝色通道的强度值</span></span><br><span class="line">blue = img[<span class="number">100</span>,<span class="number">100</span>,<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 修改某个位置的像素值</span></span><br><span class="line">img[<span class="number">100</span>,<span class="number">100</span>] = [<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>]</span><br></pre></td></tr></table></figure>
<h4 id="获取图像属性"><a href="#获取图像属性" class="headerlink" title="获取图像属性"></a>获取图像属性</h4><p>图像属性包括行数，列数和通道数，图像数据类型，像素数等。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">属性</th>
<th style="text-align:left">API</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">形状</td>
<td style="text-align:left">img.shape</td>
</tr>
<tr>
<td style="text-align:left">图像大小</td>
<td style="text-align:left">img.size</td>
</tr>
<tr>
<td style="text-align:left">数据类型</td>
<td style="text-align:left">img.dtype</td>
</tr>
</tbody>
</table>
</div>
<h4 id="图像通道的拆分-合并"><a href="#图像通道的拆分-合并" class="headerlink" title="图像通道的拆分/合并"></a>图像通道的拆分/合并</h4><p>有时需要在B，G，R通道图像上单独工作。在这种情况下，需要将BGR图像分割为单个通道。或者在其他情况下，可能需要将这些单独的通道合并到BGR图像。你可以通过以下方式完成。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通道拆分</span></span><br><span class="line">b,g,r = cv.split(img)</span><br><span class="line"><span class="comment"># 通道合并</span></span><br><span class="line">img = cv.merge((b,g,r))</span><br></pre></td></tr></table></figure>
<h4 id="色彩空间的改变"><a href="#色彩空间的改变" class="headerlink" title="色彩空间的改变"></a>色彩空间的改变</h4><p>OpenCV中有150多种颜色空间转换方法。最广泛使用的转换方法有两种，BGR↔Gray和BGR↔HSV。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.cvtColor(input_image，flag)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>input_image: 进行颜色空间转换的图像</li>
<li>flag: 转换类型<ul>
<li>cv.COLOR_BGR2GRAY : BGR↔Gray</li>
<li>cv.COLOR_BGR2HSV: BGR→HSV</li>
</ul>
</li>
</ul>
<h3 id="算数操作"><a href="#算数操作" class="headerlink" title="算数操作"></a>算数操作</h3><h4 id="图像的加法"><a href="#图像的加法" class="headerlink" title="图像的加法"></a>图像的加法</h4><p>你可以使用OpenCV的cv.add()函数把两幅图像相加，或者可以简单地通过numpy操作添加两个图像，如res = img1 + img2。两个图像应该具有相同的大小和类型，或者第二个图像可以是标量值。</p>
<p><strong>注意：OpenCV加法和Numpy加法之间存在差异。OpenCV的加法是饱和操作，而Numpy添加是模运算。</strong></p>
<p>参考以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.uint8([<span class="number">250</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = np.uint8([<span class="number">10</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>( cv.add(x,y) ) <span class="comment"># 250+10 = 260 =&gt; 255</span></span><br><span class="line">[[<span class="number">255</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>( x+y )          <span class="comment"># 250+10 = 260 % 256 = 4</span></span><br><span class="line">[<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>这种差别在你对两幅图像进行加法时会更加明显。OpenCV 的结果会更好一点。所以我们尽量使用 OpenCV 中的函数。</p>
<p>我们将下面两幅图像：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191016154526370.png" alt="image-20191016154526370" style="zoom:50%;" /></p>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img1 = cv.imread(<span class="string">&quot;view.jpg&quot;</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">&quot;rain.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 加法操作</span></span><br><span class="line">img3 = cv.add(img1,img2) <span class="comment"># cv中的加法</span></span><br><span class="line">img4 = img1+img2 <span class="comment"># 直接相加</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img3[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;cv中的加法&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(img4[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;直接相加&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191016154714377.png" alt="image-20191016154714377" style="zoom: 50%;" /></p>
<h4 id="图像的混合"><a href="#图像的混合" class="headerlink" title="图像的混合"></a>图像的混合</h4><p>这其实也是加法，但是不同的是两幅图像的权重不同，这就会给人一种混合或者透明的感觉。图像混合的计算公式如下：</p>
<blockquote>
<p>g(x) = (1−α)f0(x) + αf1(x)</p>
</blockquote>
<p>通过修改 α 的值（0 → 1），可以实现非常炫酷的混合。</p>
<p>现在我们把两幅图混合在一起。第一幅图的权重是0.7，第二幅图的权重是0.3。函数cv2.addWeighted()可以按下面的公式对图片进行混合操作。</p>
<blockquote>
<p>dst = α⋅img1 + β⋅img2 + γ</p>
</blockquote>
<p>这里γ取为零。</p>
<p>参考以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img1 = cv.imread(<span class="string">&quot;view.jpg&quot;</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">&quot;rain.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 图像混合</span></span><br><span class="line">img3 = cv.addWeighted(img1,<span class="number">0.7</span>,img2,<span class="number">0.3</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">plt.imshow(img3[:,:,::-<span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>窗口将如下图显示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191016161128720.png" alt="image-20191016161128720" style="zoom: 80%;" /></p>
<h2 id="OpenCV图像处理"><a href="#OpenCV图像处理" class="headerlink" title="OpenCV图像处理"></a>OpenCV图像处理</h2><ul>
<li>图像的几何变换</li>
<li>图像的形态学转换</li>
<li>图像的平滑方法</li>
<li>直方图的方法</li>
<li>边缘检测的方法</li>
<li>模板匹配和霍夫变换的应用</li>
</ul>
<h3 id="几何变换"><a href="#几何变换" class="headerlink" title="几何变换"></a>几何变换</h3><h4 id="图像缩放"><a href="#图像缩放" class="headerlink" title="图像缩放"></a>图像缩放</h4><p>缩放是对图像的大小进行调整，即使图像放大或缩小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv2.resize(src, dsize, fx=<span class="number">0</span>, fy=<span class="number">0</span>, interpolation=cv2.INTER_LINEAR)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li><p>src : 输入图像</p>
</li>
<li><p>dsize: 绝对尺寸，直接指定调整后图像的大小</p>
</li>
<li><p>fx,fy: 相对尺寸，将dsize设置为None，然后将fx和fy设置为比例因子即可</p>
</li>
<li><p>interpolation：插值方法，</p>
<p>| 插值              | 含义                   |<br>| ————————- | ——————————— |<br>| cv2.INTER_LINEAR  | 双线性插值法           |<br>| cv2.INTER_NEAREST | 最近邻插值             |<br>| cv2.INTER_AREA    | 像素区域重采样（默认） |<br>| cv2.INTER_CUBIC   | 双三次插值             |</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="comment"># 1. 读取图片</span></span><br><span class="line">img1 = cv.imread(<span class="string">&quot;./image/dog.jpeg&quot;</span>)</span><br><span class="line"><span class="comment"># 2.图像缩放</span></span><br><span class="line"><span class="comment"># 2.1 绝对尺寸</span></span><br><span class="line">rows,cols = img1.shape[:<span class="number">2</span>]</span><br><span class="line">res = cv.resize(img1,(<span class="number">2</span>*cols,<span class="number">2</span>*rows),interpolation=cv.INTER_CUBIC)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 相对尺寸</span></span><br><span class="line">res1 = cv.resize(img1,<span class="literal">None</span>,fx=<span class="number">0.5</span>,fy=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line"><span class="comment"># 3.1 使用opencv显示图像(不推荐)</span></span><br><span class="line">cv.imshow(<span class="string">&quot;orignal&quot;</span>,img1)</span><br><span class="line">cv.imshow(<span class="string">&quot;enlarge&quot;</span>,res)</span><br><span class="line">cv.imshow(<span class="string">&quot;shrink）&quot;</span>,res1)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.2 使用matplotlib显示图像</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">3</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(res[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;绝对尺度（放大）&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(img1[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">2</span>].imshow(res1[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">2</span>].set_title(<span class="string">&quot;相对尺度（缩小）&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926143500645.png" alt="image-20190926143500645" style="zoom: 50%;" /></p>
<h4 id="图像平移"><a href="#图像平移" class="headerlink" title="图像平移"></a>图像平移</h4><p>图像平移将图像按照指定方向和距离，移动到相应的位置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.warpAffine(img, M, dsize)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li><p>img: 输入图像</p>
</li>
<li><p>M： 2∗3移动矩阵</p>
<p>对于$(x,y)$处的像素点，要把它移动到处时$(x+t_x,y+t_y)$，M矩阵应如下设置：</p>
<script type="math/tex; mode=display">
M=\begin{bmatrix} 1&0&t_x\\ 0&1&t_y\\ \end{bmatrix}</script><p>注意：将$M$设置为np.float32类型的Numpy数组。</p>
</li>
<li><p>dsize: 输出背景图像的大小（<strong>注意：输出图像的大小，它应该是(宽度，高度)的形式。请记住,width=列数，height=行数。</strong>）</p>
</li>
</ul>
<p>示例：需求是将图像的像素点移动(50,100)的距离：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1. 读取图像</span></span><br><span class="line">img1 = cv.imread(<span class="string">&quot;./image/image2.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 图像平移</span></span><br><span class="line">rows,cols = img1.shape[:<span class="number">2</span>]</span><br><span class="line">M = M = np.float32([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">100</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>]])<span class="comment"># 平移矩阵</span></span><br><span class="line">dst = cv.warpAffine(img1,M,(cols,rows))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 图像显示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img1[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(dst[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;平移后结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926151127550.png" alt="image-20190926151127550" style="zoom: 50%;" /></p>
<h4 id="图像旋转"><a href="#图像旋转" class="headerlink" title="图像旋转"></a>图像旋转</h4><p>图像旋转是指图像按照某个位置转动一定角度的过程，旋转中图像仍保持这原始尺寸。图像旋转后图像的水平对称轴、垂直对称轴及中心坐标原点都可能会发生变换，因此需要对图像旋转中的坐标进行相应转换。</p>
<p>那图像是怎么进行旋转的呢？如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023102648731.png" alt="image-20191023102648731" style="zoom: 67%;" /></p>
<p>假设图像逆时针旋转$\theta$，则根据坐标转换可得旋转转换为：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023102927643.png" alt="image-20191023102927643" style="zoom: 50%;" /></p>
<p>其中：<img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023103038145.png" alt="image-20191023103038145" style="zoom: 50%;" /></p>
<p>带入上面的公式中，有：<img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023103106568.png" alt="image-20191023103106568" style="zoom:50%;" /></p>
<p>也可以写成：$\begin{bmatrix}x’&amp; y’&amp;1\end{bmatrix}=\begin{bmatrix}x&amp; y&amp;1\end{bmatrix}\begin{bmatrix} \cos\theta&amp;-\sin\theta&amp;0\\ \sin\theta&amp;\cos\theta&amp;0\\0&amp;0&amp;1 \end{bmatrix}$</p>
<p>同时我们要修正原点的位置，因为原图像中的坐标原点在图像的左上角，经过旋转后图像的大小会有所变化，原点也需要修正。</p>
<p>假设在旋转的时候是以旋转中心为坐标原点的，旋转结束后还需要将坐标原点移到图像左上角，也就是还要进行一次变换。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023105453003.png" alt="image-20191023105453003" style="zoom:67%;" /></p>
<p><strong>在OpenCV中图像旋转首先根据旋转角度和旋转中心获取旋转矩阵，然后根据旋转矩阵进行变换，即可实现任意角度和任意中心的旋转效果。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv2.getRotationMatrix2D(center, angle, scale)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>center：旋转中心</li>
<li>angle：旋转角度</li>
<li>scale：缩放比例</li>
</ul>
<p>返回：</p>
<ul>
<li>M：旋转矩阵</li>
</ul>
<p>调用cv.warpAffine完成图像的旋转，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&quot;./image/image2.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 图像旋转</span></span><br><span class="line">rows,cols = img.shape[:<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 2.1 生成旋转矩阵</span></span><br><span class="line">M = cv.getRotationMatrix2D((cols/<span class="number">2</span>,rows/<span class="number">2</span>),<span class="number">90</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 2.2 进行旋转变换</span></span><br><span class="line">dst = cv.warpAffine(img,M,(cols,rows))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 图像展示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img1[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(dst[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;旋转后结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926152854704.png" alt="image-20190926152854704" style="zoom:50%;" /></p>
<h4 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h4><p>图像的仿射变换涉及到图像的形状位置角度的变化，是深度学习预处理中常到的功能,仿射变换主要是对图像的缩放，旋转，翻转和平移等操作的组合。</p>
<p>那什么是图像的仿射变换，如下图所示，图1中的点1, 2 和 3 与图二中三个点一一映射, 仍然形成三角形, 但形状已经大大改变，通过这样两组三点（感兴趣点）求出仿射变换， 接下来我们就能把仿射变换应用到图像中所有的点中，就完成了图像的仿射变换。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023115222617.png" alt="image-20191023115222617" style="zoom: 50%;" /></p>
<p>在OpenCV中，仿射变换的矩阵是一个2×3的矩阵，$M=\begin{bmatrix}A &amp; B\end{bmatrix}=\begin{bmatrix} a_{00}&amp;a_{01}&amp;b_0\\ a_{10}&amp;a_{11}&amp;b_1\\ \end{bmatrix}$</p>
<p>其中左边的2×2子矩阵$A$是线性变换矩阵，右边的2×1子矩阵$B$是平移项：$A=\begin{bmatrix} a_{00}&amp;a_{01}\\ a_{10}&amp;a_{11}\\ \end{bmatrix},B=\begin{bmatrix} b_0\\ b_1\\ \end{bmatrix}$</p>
<p>对于图像上的任一位置(x,y)，仿射变换执行的是如下的操作：$T_{affine}=A\left[\begin{matrix} x\\ y \end{matrix} \right]+B=M\left[\begin{matrix}x\\y\\1\end{matrix}\right]$</p>
<p>需要注意的是，对于图像而言，宽度方向是x，高度方向是y，坐标的顺序和图像像素对应下标一致。所以原点的位置不是左下角而是左上角，y的方向也不是向上，而是向下。</p>
<p>在仿射变换中，原图中所有的平行线在结果图像中同样平行。为了创建这个矩阵我们需要从原图像中找到三个点以及他们在输出图像中的位置。然后cv2.getAﬃneTransform 会创建一个 2x3 的矩阵，最后这个矩阵会被传给函数 cv2.warpAﬃne。</p>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像读取</span></span><br><span class="line">img = cv.imread(<span class="string">&quot;./image/image2.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 仿射变换</span></span><br><span class="line">rows,cols = img.shape[:<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 2.1 创建变换矩阵</span></span><br><span class="line">pts1 = np.float32([[<span class="number">50</span>,<span class="number">50</span>],[<span class="number">200</span>,<span class="number">50</span>],[<span class="number">50</span>,<span class="number">200</span>]])</span><br><span class="line">pts2 = np.float32([[<span class="number">100</span>,<span class="number">100</span>],[<span class="number">200</span>,<span class="number">50</span>],[<span class="number">100</span>,<span class="number">250</span>]])</span><br><span class="line">M = cv.getAffineTransform(pts1,pts2)</span><br><span class="line"><span class="comment"># 2.2 完成仿射变换</span></span><br><span class="line">dst = cv.warpAffine(img,M,(cols,rows))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(dst[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;仿射后结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926161027173.png" alt="image-20190926161027173" style="zoom: 50%;" /></p>
<h4 id="透射变换"><a href="#透射变换" class="headerlink" title="透射变换"></a>透射变换</h4><p>透射变换是视角变化的结果，是指利用透视中心、像点、目标点三点共线的条件，按透视旋转定律使承影面（透视面）绕迹线（透视轴）旋转某一角度，破坏原有的投影光线束，仍能保持承影面上投影几何图形不变的变换。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191023130051717.png" alt="image-20191023130051717" style="zoom:67%;" /></p>
<p>它的本质将图像投影到一个新的视平面，其通用变换公式为：$\begin{bmatrix}x’&amp; y’&amp; z’\end{bmatrix}=\begin{bmatrix}u&amp; v&amp;w\end{bmatrix}\begin{bmatrix} a_{00}&amp;a_{01}&amp;a_{02}\\ a_{10}&amp;a_{11}&amp;a_{12}\\a_{20}&amp;a_{21}&amp;a_{22} \end{bmatrix}$</p>
<p>其中，(u,v)是原始的图像像素坐标，w取值为1，(x=x’/z’,y=y’/z’)是透射变换后的结果。后面的矩阵称为透视变换矩阵，一般情况下，我们将其分为三部分：</p>
<script type="math/tex; mode=display">
T=\begin{bmatrix} a_{00}&a_{01}&a_{02}\\ a_{10}&a_{11}&a_{12}\\a_{20}&a_{21}&a_{22} \end{bmatrix}=\begin{bmatrix}T1&T2 \\ T3&a_{22}\end{bmatrix}</script><p>其中：T1表示对图像进行线性变换，T2对图像进行平移，T3表示对图像进行投射变换，$a_{22}$一般设为1.</p>
<p>在opencv中，我们要找到四个点，其中任意三个不共线，然后获取变换矩阵T，再进行透射变换。通过函数cv.getPerspectiveTransform找到变换矩阵，将cv.warpPerspective应用于此3x3变换矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&quot;./image/image2.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># 2 透射变换</span></span><br><span class="line">rows,cols = img.shape[:<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 2.1 创建变换矩阵</span></span><br><span class="line">pts1 = np.float32([[<span class="number">56</span>,<span class="number">65</span>],[<span class="number">368</span>,<span class="number">52</span>],[<span class="number">28</span>,<span class="number">387</span>],[<span class="number">389</span>,<span class="number">390</span>]])</span><br><span class="line">pts2 = np.float32([[<span class="number">100</span>,<span class="number">145</span>],[<span class="number">300</span>,<span class="number">100</span>],[<span class="number">80</span>,<span class="number">290</span>],[<span class="number">310</span>,<span class="number">300</span>]])</span><br><span class="line"></span><br><span class="line">T = cv.getPerspectiveTransform(pts1,pts2)</span><br><span class="line"><span class="comment"># 2.2 进行变换</span></span><br><span class="line">dst = cv.warpPerspective(img,T,(cols,rows))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(dst[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;透射后结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926162913916.png" alt="image-20190926162913916" style="zoom: 50%;" /></p>
<h4 id="图像金字塔"><a href="#图像金字塔" class="headerlink" title="图像金字塔"></a>图像金字塔</h4><p>图像金字塔是图像多尺度表达的一种，最主要用于图像的分割，是一种以多分辨率来解释图像的有效但概念简单的结构。</p>
<p>图像金字塔用于机器视觉和图像压缩，一幅图像的金字塔是一系列以金字塔形状排列的分辨率逐步降低，且来源于同一张原始图的图像集合。其通过梯次向下采样获得，直到达到某个终止条件才停止采样。</p>
<p>金字塔的底部是待处理图像的高分辨率表示，而顶部是低分辨率的近似，层级越高，图像越小，分辨率越低。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/timg.jpeg" alt="timg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cv.pyrUp(img)       <span class="comment">#对图像进行上采样</span></span><br><span class="line">cv.pyrDown(img)        <span class="comment">#对图像进行下采样</span></span><br></pre></td></tr></table></figure>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像读取</span></span><br><span class="line">img = cv.imread(<span class="string">&quot;./image/image2.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># 2 进行图像采样</span></span><br><span class="line">up_img = cv.pyrUp(img)  <span class="comment"># 上采样操作</span></span><br><span class="line">img_1 = cv.pyrDown(img)  <span class="comment"># 下采样操作</span></span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">cv.imshow(<span class="string">&#x27;enlarge&#x27;</span>, up_img)</span><br><span class="line">cv.imshow(<span class="string">&#x27;original&#x27;</span>, img)</span><br><span class="line">cv.imshow(<span class="string">&#x27;shrink&#x27;</span>, img_1)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20230226174240926.png" alt="image-20230226174240926" style="zoom: 40%;" /></p>
<h3 id="形态学操作"><a href="#形态学操作" class="headerlink" title="形态学操作"></a>形态学操作</h3><h4 id="连通性"><a href="#连通性" class="headerlink" title="连通性"></a>连通性</h4><p>在图像中，最小的单位是像素，每个像素周围有8个邻接像素，常见的邻接关系有3种：4邻接、D邻接和8邻接。分别如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926185646667.png" alt="image-20190926185646667" style="zoom:67%;" /></p>
<ul>
<li>4邻接：像素p(x,y)的4邻域是：(x+1,y)；(x-1,y)；(x,y+1)；(x,y-1)，用$N_4(p)$表示像素p的4邻接</li>
<li>D邻接：像素p(x,y)的D邻域是：对角上的点 (x+1,y+1)；(x+1,y-1)；(x-1,y+1)；(x-1,y-1)，用$N_D(p)$表示像素p的D邻域</li>
<li>8邻接：像素p(x,y)的8邻域是： 4邻域的点 ＋ D邻域的点，用$N_8(p)$表示像素p的8邻域</li>
</ul>
<p><strong>连通性</strong>是描述区域和边界的重要概念，两个像素连通的两个必要条件是：</p>
<ol>
<li>两个像素的位置是否相邻</li>
<li>两个像素的灰度值是否满足特定的相 似性准则（或者是否相等</li>
</ol>
<p>根据连通性的定义，有4联通、8联通和m联通三种。</p>
<ul>
<li><p>4联通：对于具有值$V$的像素$p$和$q$，如果$q$在集合$N_4(p)$中，则称这两个像素是4连通。</p>
</li>
<li><p>8联通：对于具有值$V$的像素$p$和$q$，如果$q$在集合$N_8(p)$中，则称这两个像素是8连通。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190926185504256.png" alt="image-20190926185504256" style="zoom: 50%;" /></p>
</li>
<li><p>对于具有值$V$的像素$p$和$q$，如果：</p>
<ol>
<li>$q$在集合$N_4(p)$中，或</li>
<li>$q$在集合$N_D(p)$中，并且$N_4(p)$与$N_4(q)$的交集为空（没有值$V$的像素）</li>
</ol>
<p>则称这两个像素是$m$连通的，即4连通和D连通的混合连通。</p>
</li>
</ul>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927101630929.png" alt="image-20190927101630929" style="zoom: 80%;" /></p>
<h4 id="腐蚀和膨胀"><a href="#腐蚀和膨胀" class="headerlink" title="腐蚀和膨胀"></a>腐蚀和膨胀</h4><p>腐蚀和膨胀是最基本的形态学操作，腐蚀和膨胀都是针对白色部分（高亮部分）而言的。</p>
<p>膨胀就是使图像中高亮部分扩张，效果图拥有比原图更大的高亮区域；腐蚀是原图中的高亮区域被蚕食，效果图拥有比原图更小的高亮区域。膨胀是求局部最大值的操作，腐蚀是求局部最小值的操作。</p>
<p><strong>腐蚀</strong></p>
<p>具体操作是：<strong>用一个结构元素扫描图像中的每一个像素，用结构元素中的每一个像素与其覆盖的像素做“与”操作，如果都为1，则该像素为1，否则为0</strong>。如下图所示，结构A被结构B腐蚀后：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927105316401.png" alt="image-20190927105316401" style="zoom:80%;" /></p>
<p>腐蚀的<strong>作用</strong>是消除物体边界点，使目标缩小，可以消除小于结构元素的噪声点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.erode(img, kernel, iterations)</span><br></pre></td></tr></table></figure>
<ul>
<li>img: 要处理的图像</li>
<li>kernel: 核结构</li>
<li>iterations: 腐蚀的次数，默认是1</li>
</ul>
<p><strong>膨胀</strong></p>
<p>具体操作是：用一个结构元素扫描图像中的每一个像素，用结构元素中的每一个像素与其覆盖的像素做“与”操作，如果都为0，则该像素为0，否则为1。如下图所示，结构A被结构B膨胀后：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927110711458.png" alt="image-20190927110711458" style="zoom: 80%;" /></p>
<p>膨胀的作用是将与物体接触的所有背景点合并到物体中，使目标增大，可添补目标中的孔洞。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.dilate(img,kernel,iterations)</span><br></pre></td></tr></table></figure>
<ul>
<li>img: 要处理的图像</li>
<li>kernel: 核结构</li>
<li>iterations: 腐蚀的次数，默认是1</li>
</ul>
<p>我们使用一个5*5的卷积核实现腐蚀和膨胀的运算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&quot;./image/image3.png&quot;</span>)</span><br><span class="line"><span class="comment"># 2 创建核结构</span></span><br><span class="line">kernel = np.ones((<span class="number">5</span>, <span class="number">5</span>), np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 图像腐蚀和膨胀</span></span><br><span class="line">erosion = cv.erode(img, kernel) <span class="comment"># 腐蚀</span></span><br><span class="line">dilate = cv.dilate(img,kernel) <span class="comment"># 膨胀</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 图像展示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">3</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img)</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(erosion)</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;腐蚀后结果&quot;</span>)</span><br><span class="line">axes[<span class="number">2</span>].imshow(dilate)</span><br><span class="line">axes[<span class="number">2</span>].set_title(<span class="string">&quot;膨胀后结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927151844574.png" alt="image-20190927151844574" style="zoom: 50%;" /></p>
<h4 id="开闭运算"><a href="#开闭运算" class="headerlink" title="开闭运算"></a>开闭运算</h4><p>开运算和闭运算是将腐蚀和膨胀按照一定的次序进行处理。 但这两者并不是可逆的，即先开后闭并不能得到原来的图像。</p>
<p><strong>开运算</strong></p>
<p>开运算是先腐蚀后膨胀，其<strong>作用</strong>是：分离物体，消除小区域。<strong>特点</strong>：消除噪点，去除小的干扰块，而不影响原来的图像。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927142206425.png" alt="image-20190927142206425" style="zoom:80%;" /></p>
<p><strong>闭运算</strong></p>
<p>闭运算与开运算相反，是先膨胀后腐蚀，<strong>作用</strong>是消除/“闭合”物体里面的孔洞，<strong>特点</strong>：可以填充闭合区域。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927142923777.png" alt="image-20190927142923777" style="zoom:80%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.morphologyEx(img, op, kernel)</span><br></pre></td></tr></table></figure>
<ul>
<li>img: 要处理的图像</li>
<li>op: 处理方式：若进行开运算，则设为cv.MORPH_OPEN，若进行闭运算，则设为cv.MORPH_CLOSE</li>
<li>Kernel： 核结构</li>
</ul>
<p>使用10*10的核结构对卷积进行开闭运算的实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img1 = cv.imread(<span class="string">&quot;./image/image5.png&quot;</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">&quot;./image/image6.png&quot;</span>)</span><br><span class="line"><span class="comment"># 2 创建核结构</span></span><br><span class="line">kernel = np.ones((<span class="number">10</span>, <span class="number">10</span>), np.uint8)</span><br><span class="line"><span class="comment"># 3 图像的开闭运算</span></span><br><span class="line">cvOpen = cv.morphologyEx(img1,cv.MORPH_OPEN,kernel) <span class="comment"># 开运算</span></span><br><span class="line">cvClose = cv.morphologyEx(img2,cv.MORPH_CLOSE,kernel)<span class="comment"># 闭运算</span></span><br><span class="line"><span class="comment"># 4 图像展示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">2</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].imshow(img1)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].imshow(cvOpen)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].set_title(<span class="string">&quot;开运算结果&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].imshow(img2)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].imshow(cvClose)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].set_title(<span class="string">&quot;闭运算结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927153400823.png" alt="image-20190927153400823" style="zoom: 67%;" /></p>
<h4 id="礼帽和黑帽"><a href="#礼帽和黑帽" class="headerlink" title="礼帽和黑帽"></a>礼帽和黑帽</h4><p><strong>礼帽运算</strong></p>
<p>原图像与“开运算“的结果图之差，如下式计算：<code>dst = tophat(src, element) = src - open(src, element)</code></p>
<p>因为开运算带来的结果是放大了裂缝或者局部低亮度的区域，因此，从原图中减去开运算后的图，得到的效果图突出了比原图轮廓周围的区域更明亮的区域，且这一操作和选择的核的大小相关。</p>
<p>礼帽运算用来分离比邻近点亮一些的斑块。当一幅图像具有大幅的背景的时候，而微小物品比较有规律的情况下，可以使用礼帽运算进行背景提取。</p>
<p><strong>黑帽运算</strong></p>
<p>为”闭运算“的结果图与原图像之差。数学表达式为：<code>dst = blackhat(src, element) = close(src, element) - src</code></p>
<p>黑帽运算后的效果图突出了比原图轮廓周围的区域更暗的区域，且这一操作和选择的核的大小相关。</p>
<p>黑帽运算用来分离比邻近点暗一些的斑块。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.morphologyEx(img, op, kernel)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>img: 要处理的图像</p>
</li>
<li><p>op: 处理方式：</p>
<p>| 参数              | 功能     |<br>| ————————- | ———— |<br>| cv.MORPH_CLOSE    | 闭运算   |<br>| cv.MORPH_OPEN     | 开运算   |<br>| cv.MORPH_TOPHAT   | 礼帽运算 |<br>| cv.MORPH_BLACKHAT | 黑帽运算 |</p>
</li>
<li><p>Kernel：核结构</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img1 = cv.imread(<span class="string">&quot;./image/image5.png&quot;</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">&quot;./image/image6.png&quot;</span>)</span><br><span class="line"><span class="comment"># 2 创建核结构</span></span><br><span class="line">kernel = np.ones((<span class="number">10</span>, <span class="number">10</span>), np.uint8)</span><br><span class="line"><span class="comment"># 3 图像的礼帽和黑帽运算</span></span><br><span class="line">cvOpen = cv.morphologyEx(img1,cv.MORPH_TOPHAT,kernel) <span class="comment"># 礼帽运算</span></span><br><span class="line">cvClose = cv.morphologyEx(img2,cv.MORPH_BLACKHAT,kernel)  <span class="comment"># 黑帽运算</span></span><br><span class="line"><span class="comment"># 4 图像显示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">2</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].imshow(img1)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].imshow(cvOpen)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].set_title(<span class="string">&quot;礼帽运算结果&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].imshow(img2)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].imshow(cvClose)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].set_title(<span class="string">&quot;黑帽运算结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927154018177.png" alt="image-20190927154018177" style="zoom:67%;" /></p>
<h3 id="图像平滑"><a href="#图像平滑" class="headerlink" title="图像平滑"></a>图像平滑</h3><p>图像平滑从信号处理的角度看就是去除其中的高频信息，保留低频信息。因此我们可以对图像实施低通滤波。低通滤波可以去除图像中的噪声，对图像进行平滑。</p>
<p>根据滤波器的不同可分为均值滤波，高斯滤波，中值滤波， 双边滤波。</p>
<h4 id="图像噪声"><a href="#图像噪声" class="headerlink" title="图像噪声"></a>图像噪声</h4><p>由于图像采集、处理、传输等过程不可避免的会受到噪声的污染，妨碍人们对图像理解及分析处理。常见的图像噪声有高斯噪声、椒盐噪声等。</p>
<h5 id="椒盐噪声"><a href="#椒盐噪声" class="headerlink" title="椒盐噪声"></a>椒盐噪声</h5><p>椒盐噪声也称为脉冲噪声，是图像中经常见到的一种噪声，它是一种随机出现的白点或者黑点，可能是亮的区域有黑色像素或是在暗的区域有白色像素（或是两者皆有）。椒盐噪声的成因可能是影像讯号受到突如其来的强烈干扰而产生、类比数位转换器或位元传输错误等。例如失效的感应器导致像素值为最小值，饱和的感应器导致像素值为最大值。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927163654718.png" alt="image-20190927163654718" style="zoom: 50%;" /></p>
<h5 id="高斯噪声"><a href="#高斯噪声" class="headerlink" title="高斯噪声"></a>高斯噪声</h5><p>高斯噪声是指噪声密度函数服从高斯分布的一类噪声。由于高斯噪声在空间和频域中数学上的易处理性，这种噪声（也称为正态噪声）模型经常被用于实践中。高斯随机变量z的概率密度函数由下式给出：$p(z)=\frac{1}{\sqrt{2π}σ}e\frac{−(z−μ)^2}{2σ^2}$</p>
<p>其中$z$表示灰度值，$μ$表示$z$的平均值或期望值，$σ$表示$z$的标准差。标准差的平方$σ2$称为$z$的方差。高斯函数的曲线如图所示。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927164749878.png" alt="image-20190927164749878" style="zoom:67%;" /></p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190927164045611.png" alt="image-20190927164045611" style="zoom: 50%;" /></p>
<h4 id="均值滤波"><a href="#均值滤波" class="headerlink" title="均值滤波"></a>均值滤波</h4><p>采用均值滤波模板对图像噪声进行滤除。令$S_{xy}$表示中心在(x, y)点，尺寸为 m×n 的矩形子图像窗口的坐标组。 均值滤波器可表示为：</p>
<script type="math/tex; mode=display">
\hat{f}(x,y)=\frac{1}{mn}\sum_{(s,t)∈S_(xy)}g(s,t)</script><p>由一个归一化卷积框完成的。它只是用卷积框覆盖区域所有像素的平均值来代替中心元素。</p>
<p>例如，3x3标准化的平均过滤器如下所示：</p>
<script type="math/tex; mode=display">
K=\frac{1}{9}\begin{bmatrix} 1&1&1\\ 1&1&1\\ 1&1&1 \end{bmatrix}</script><p><strong>均值滤波的优点是算法简单，计算速度较快，缺点是在去噪的同时去除了很多细节部分，将图像变得模糊。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.blur(src, ksize, anchor, borderType)</span><br></pre></td></tr></table></figure>
<ul>
<li>src：输入图像</li>
<li>ksize：卷积核的大小</li>
<li>anchor：默认值 (-1,-1) ，表示核中心</li>
<li>borderType：边界类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像读取</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/dogsp.jpeg&#x27;</span>)</span><br><span class="line"><span class="comment"># 2 均值滤波</span></span><br><span class="line">blur = cv.blur(img,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;原图&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(blur[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;均值滤波后结果&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928102258185.png" alt="image-20190928102258185" style="zoom: 50%;" /></p>
<h4 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h4><p>二维高斯是构建高斯滤波器的基础，其概率分布函数如下所示：</p>
<script type="math/tex; mode=display">
G(x,y)=\frac{1}{2\pi σ^2}exp\{-\frac{x^2+y^2}{2σ^2}\}</script><p>$G(x,y)$的分布是一个突起的帽子的形状。这里的$σ$可以看作两个值，一个是x方向的标准差$σ_x$，另一个是y方向的标准差$σ_y$。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928104118332.png" alt="image-20190928104118332" style="zoom:67%;" /></p>
<p>当$σ_x$和$σ_y$取值越大，整个形状趋近于扁平；当$σ_x$和$σ_y$取值越小，整个形状越突起。</p>
<p>正态分布是一种钟形曲线，越接近中心，取值越大，越远离中心，取值越小。计算平滑结果时，只需要将”中心点”作为原点，其他点按照其在正态曲线上的位置，分配权重，就可以得到一个加权平均值。</p>
<p>高斯平滑在从图像中去除高斯噪声方面非常有效。</p>
<p><strong>高斯平滑的流程：</strong></p>
<ul>
<li>首先确定权重矩阵</li>
</ul>
<p>假定中心点的坐标是（0,0），那么距离它最近的8个点的坐标如下：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110341406.png" alt="image-20190928110341406" style="zoom: 40%;" /></p>
<p>更远的点以此类推。</p>
<p>为了计算权重矩阵，需要设定$σ$的值。假定$σ=1.5$，则模糊半径为1的权重矩阵如下：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110425845.png" alt="image-20190928110425845" style="zoom: 40%;" /></p>
<p>这9个点的权重总和等于0.4787147，如果只计算这9个点的加权平均，还必须让它们的权重之和等于1，因此上面9个值还要分别除以0.4787147，得到最终的权重矩阵。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110455467.png" alt="image-20190928110455467" style="zoom:40%;" /></p>
<ul>
<li>计算高斯模糊</li>
</ul>
<p>有了权重矩阵，就可以计算高斯模糊的值了。</p>
<p>假设现有9个像素点，灰度值（0-255）如下：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110522272.png" alt="image-20190928110522272" style="zoom:40%;" /></p>
<p>每个点乘以对应的权重值：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110551897.png" alt="image-20190928110551897" style="zoom:40%;" /></p>
<p>得到</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928110613880.png" alt="image-20190928110613880" style="zoom:40%;" /></p>
<p>将这9个值加起来，就是中心点的高斯模糊的值。</p>
<p>对所有点重复这个过程，就得到了高斯模糊后的图像。如果原图是彩色图片，可以对RGB三个通道分别做高斯平滑。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv2.GaussianBlur(src,ksize,sigmaX,sigmay,borderType)</span><br></pre></td></tr></table></figure>
<ul>
<li>src: 输入图像</li>
<li>ksize:高斯卷积核的大小，<strong>注意</strong>：卷积核的宽度和高度都应为奇数，且可以不同</li>
<li>sigmaX: 水平方向的标准差</li>
<li>sigmaY: 垂直方向的标准差，默认值为0，表示与sigmaX相同</li>
<li>borderType:填充边界类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像读取</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/dogGasuss.jpeg&#x27;</span>)</span><br><span class="line"><span class="comment"># 2 高斯滤波</span></span><br><span class="line">blur = cv.GaussianBlur(img,(<span class="number">3</span>,<span class="number">3</span>),<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;原图&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(blur[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;高斯滤波后结果&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928111903926.png" alt="image-20190928111903926" style="zoom:50%;" /></p>
<h4 id="中值滤波"><a href="#中值滤波" class="headerlink" title="中值滤波"></a>中值滤波</h4><p>中值滤波是一种典型的非线性滤波技术，基本思想是用像素点邻域灰度值的中值来代替该像素点的灰度值。</p>
<p>中值滤波对椒盐噪声（salt-and-pepper noise）来说尤其有用，因为它不依赖于邻域内那些与典型值差别很大的值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.medianBlur(src, ksize)</span><br></pre></td></tr></table></figure>
<ul>
<li>src：输入图像</li>
<li>ksize：卷积核的大小</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像读取</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/dogsp.jpeg&#x27;</span>)</span><br><span class="line"><span class="comment"># 2 中值滤波</span></span><br><span class="line">blur = cv.medianBlur(img,<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 3 图像展示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;原图&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(blur[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;中值滤波后结果&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928102319410.png" alt="image-20190928102319410" style="zoom:50%;" /></p>
<h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><ul>
<li>掌握图像的直方图计算和显示</li>
<li>了解掩膜的应用</li>
<li>熟悉直方图均衡化，了解自适应均衡化</li>
</ul>
<h4 id="灰度直方图"><a href="#灰度直方图" class="headerlink" title="灰度直方图"></a>灰度直方图</h4><p>直方图是对数据进行统计的一种方法，并且将统计值组织到一系列实现定义好的 bin 当中。其中， bin 为直方图中经常用到的一个概念，可以译为 “直条” 或 “组距”，其数值是从数据中计算出的特征统计量，这些数据可以是诸如梯度、方向、色彩或任何其他特征。</p>
<p>图像直方图（Image Histogram）是用以表示数字图像中亮度分布的直方图，标绘了图像中每个亮度值的像素个数。这种直方图中，横坐标的左侧为较暗的区域，而右侧为较亮的区域。因此一张较暗图片的直方图中的数据多集中于左侧和中间部分，而整体明亮、只有少量阴影的图像则相反。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928144352467.png" alt="image-20190928144352467" style="zoom: 67%;" /></p>
<p>注意：直方图是根据灰度图进行绘制的，而不是彩色图像。</p>
<p>假设有一张图像的信息（灰度值 0 - 255，已知数字的范围包含 256 个值，于是可以按一定规律将这个范围分割成子区域（也就是 bins）。如：</p>
<script type="math/tex; mode=display">
[0,255]=[0,15]⋃[16,30]⋯⋃[240,255]</script><p>然后再统计每一个 bin(i) 的像素数目。可以得到下图（其中 x 轴表示 bin，y 轴表示各个 bin 中的像素个数）： </p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928145730979.png" alt="image-20190928145730979" style="zoom:67%;" /></p>
<p>直方图的一些<strong>术语和细节</strong>：</p>
<ul>
<li>dims：需要统计的特征数目。在上例中，dims = 1 ，因为仅仅统计了灰度值。</li>
<li>bins：每个特征空间子区段的数目，可译为 “直条” 或 “组距”，在上例中， bins = 16。</li>
<li>range：要统计特征的取值范围。在上例中，range = [0, 255]。</li>
</ul>
<p>直方图的<strong>意义</strong>：</p>
<ul>
<li>直方图是图像中像素强度分布的图形表达方式。   </li>
<li>它统计了每一个强度值所具有的像素个数。</li>
<li>不同的图像的直方图可能是相同的</li>
</ul>
<h4 id="计算-绘制直方图"><a href="#计算-绘制直方图" class="headerlink" title="计算/绘制直方图"></a>计算/绘制直方图</h4><p>我们使用OpenCV中的方法统计直方图，并使用matplotlib将其绘制出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv2.calcHist(images, channels, mask, histSize, ranges[,hist[,accumulate]])</span><br></pre></td></tr></table></figure>
<ul>
<li>images: 原图像。当传入函数时应该用中括号 [] 括起来，例如：[img]。</li>
<li>channels: 如果输入图像是灰度图，它的值就是 [0]；如果是彩色图像的话，传入的参数可以是 [0]，[1]，[2] 它们分别对应着通道 B，G，R。 　　</li>
<li>mask: 掩模图像。要统计整幅图像的直方图就把它设为 None。但是如果你想统计图像某一部分的直方图的话，你就需要制作一个掩模图像，并使用它。（后边有例子） 　　</li>
<li>histSize:BIN 的数目。也应该用中括号括起来，例如：[256]。 　　</li>
<li>ranges: 像素值范围，通常为 [0，256]</li>
</ul>
<p>示例：如下图，绘制相应的直方图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 直接以灰度图的方式读入</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/cat.jpeg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 2 统计灰度图</span></span><br><span class="line">histr = cv.calcHist([img],[<span class="number">0</span>],<span class="literal">None</span>,[<span class="number">256</span>],[<span class="number">0</span>,<span class="number">256</span>])</span><br><span class="line"><span class="comment"># 3 绘制灰度图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.plot(histr)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928155000064.png" alt="image-20190928155000064" style="zoom:50%;" /></p>
<h4 id="掩膜的应用"><a href="#掩膜的应用" class="headerlink" title="掩膜的应用"></a>掩膜的应用</h4><p>掩膜是用选定的图像、图形或物体，对要处理的图像进行遮挡，来控制图像处理的区域。</p>
<p>在数字图像处理中，我们通常使用二维矩阵数组进行掩膜。掩膜是由0和1组成一个二进制图像，利用该掩膜图像要处理的图像进行掩膜，其中1值的区域被处理，0 值区域被屏蔽，不会处理。</p>
<p>掩膜的主要用途是：</p>
<ul>
<li>提取感兴趣区域：用预先制作的感兴趣区掩模与待处理图像进行”与“操作，得到感兴趣区图像，感兴趣区内图像值保持不变，而区外图像值都为0。</li>
<li>屏蔽作用：用掩模对图像上某些区域作屏蔽，使其不参加处理或不参加处理参数的计算，或仅对屏蔽区作处理或统计。</li>
<li>结构特征提取：用相似性变量或图像匹配方法检测和提取图像中与掩模相似的结构特征。</li>
<li>特殊形状图像制作</li>
</ul>
<p>掩膜在遥感影像处理中使用较多，当提取道路或者河流，或者房屋时，通过一个掩膜矩阵来对图像进行像素过滤，然后将我们需要的地物或者标志突出显示出来。</p>
<p>我们使用cv.calcHist()来查找完整图像的直方图。 如果要查找图像某些区域的直方图，该怎么办？ 只需在要查找直方图的区域上创建一个白色的掩膜图像，否则创建黑色， 然后将其作为掩码mask传递即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1. 直接以灰度图的方式读入</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/cat.jpeg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 2. 创建蒙版</span></span><br><span class="line">mask = np.zeros(img.shape[:<span class="number">2</span>], np.uint8)</span><br><span class="line">mask[<span class="number">400</span>:<span class="number">650</span>, <span class="number">200</span>:<span class="number">500</span>] = <span class="number">255</span></span><br><span class="line"><span class="comment"># 3.掩模</span></span><br><span class="line">masked_img = cv.bitwise_and(img,img,mask = mask)</span><br><span class="line"><span class="comment"># 4. 统计掩膜后图像的灰度图</span></span><br><span class="line">mask_histr = cv.calcHist([img],[<span class="number">0</span>],mask,[<span class="number">256</span>],[<span class="number">1</span>,<span class="number">256</span>])</span><br><span class="line"><span class="comment"># 5. 图像展示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">2</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].imshow(img,cmap=plt.cm.gray)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].imshow(mask,cmap=plt.cm.gray)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].set_title(<span class="string">&quot;蒙版数据&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].imshow(masked_img,cmap=plt.cm.gray)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].set_title(<span class="string">&quot;掩膜后数据&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].plot(mask_histr)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].grid()</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].set_title(<span class="string">&quot;灰度直方图&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928160241831.png" alt="image-20190928160241831" style="zoom:67%;" /></p>
<h4 id="直方图均衡化"><a href="#直方图均衡化" class="headerlink" title="直方图均衡化"></a>直方图均衡化</h4><p>想象一下，如果一副图像中的大多数像素点的像素值都集中在某一个小的灰度值值范围之内会怎样呢？如果一幅图像整体很亮，那所有的像素值的取值个数应该都会很高。所以应该把它的直方图做一个横向拉伸（如下图），就可以扩大图像像素值的分布范围，提高图像的对比度，这就是直方图均衡化要做的事情。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928162111755.png" alt="image-20190928162111755" style="zoom:67%;" /></p>
<p>“直方图均衡化”是把原始图像的灰度直方图从比较集中的某个灰度区间变成在更广泛灰度范围内的分布。直方图均衡化就是对图像进行非线性拉伸，重新分配图像像素值，使一定灰度范围内的像素数量大致相同。</p>
<p>这种方法提高图像整体的对比度，特别是有用数据的像素值分布比较接近时，在X光图像中使用广泛，可以提高骨架结构的显示，另外在曝光过度或不足的图像中可以更好的突出细节。</p>
<p>使用opencv进行直方图统计时，使用的是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dst = cv.equalizeHist(img)</span><br></pre></td></tr></table></figure>
<ul>
<li>img: 灰度图像</li>
<li>dst : 均衡化后的结果</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1. 直接以灰度图的方式读入</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/cat.jpeg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 2. 均衡化处理</span></span><br><span class="line">dst = cv.equalizeHist(img)</span><br><span class="line"><span class="comment"># 3. 结果展示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">2</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img,cmap=plt.cm.gray)</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(dst,cmap=plt.cm.gray)</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;均衡化后结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928163431354.png" alt="image-20190928163431354" style="zoom: 67%;" /></p>
<h4 id="自适应的直方图均衡化"><a href="#自适应的直方图均衡化" class="headerlink" title="自适应的直方图均衡化"></a>自适应的直方图均衡化</h4><p>上述的直方图均衡，我们考虑的是图像的全局对比度。 的确在进行完直方图均衡化之后，图片背景的对比度被改变了，在猫腿这里太暗，我们丢失了很多信息，所以在许多情况下，这样做的效果并不好。如下图所示，对比下两幅图像中雕像的画面，由于太亮我们丢失了很多信息。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191024105039014.png" alt="image-20191024105039014" style="zoom:67%;" /></p>
<p>为了解决这个问题， 需要使用自适应的直方图均衡化。 此时， 整幅图像会被分成很多小块，这些小块被称为“tiles”（在 OpenCV 中 tiles 的 大小默认是 8x8），然后再对每一个小块分别进行直方图均衡化。 所以在每一个的区域中， 直方图会集中在某一个小的区域中）。如果有噪声的话，噪声会被放大。为了避免这种情况的出现要使用对比度限制。对于每个小块来说，如果直方图中的 bin 超过对比度的上限的话，就把 其中的像素点均匀分散到其他 bins 中，然后在进行直方图均衡化。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191024105353109.png" alt="image-20191024105353109" style="zoom: 50%;" /></p>
<p>最后，为了 去除每一个小块之间的边界，再使用双线性差值，对每一小块进行拼接。</p>
<p>API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.createCLAHE(clipLimit, tileGridSize)</span><br></pre></td></tr></table></figure>
<ul>
<li>clipLimit: 对比度限制，默认是40</li>
<li>tileGridSize: 分块的大小，默认为$8∗8$</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="comment"># 1. 以灰度图形式读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/cat.jpeg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 2. 创建一个自适应均衡化的对象，并应用于图像</span></span><br><span class="line">clahe = cv.createCLAHE(clipLimit=<span class="number">2.0</span>, tileGridSize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">cl1 = clahe.apply(img)</span><br><span class="line"><span class="comment"># 3. 图像展示</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img,cmap=plt.cm.gray)</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;原图&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(cl1,cmap=plt.cm.gray)</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;自适应均衡化后的结果&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190928165605432.png" alt="image-20190928165605432" style="zoom: 50%;" /></p>
<h3 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h3><ul>
<li>了解Sobel算子，Scharr算子和拉普拉斯算子</li>
<li>掌握canny边缘检测的原理及应用</li>
</ul>
<h4 id="边缘检测原理"><a href="#边缘检测原理" class="headerlink" title="边缘检测原理"></a>边缘检测原理</h4><p>边缘检测是图像处理和计算机视觉中的基本问题，边缘检测的目的是标识数字图像中亮度变化明显的点。图像属性中的显著变化通常反映了属性的重要事件和变化。边缘的表现形式如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191024160953045.png" alt="image-20191024160953045" style="zoom:50%;" /></p>
<p>图像边缘检测大幅度地减少了数据量，并且剔除了可以认为不相关的信息，保留了图像重要的结构属性。有许多方法用于边缘检测，它们的绝大部分可以划分为两类：<strong>基于搜索</strong>和<strong>基于零穿越</strong>。</p>
<ul>
<li><p>基于搜索：通过寻找图像一阶导数中的最大值来检测边界，然后利用计算结果估计边缘的局部方向，通常采用梯度的方向，并利用此方向找到局部梯度模的最大值，代表算法是Sobel算子和Scharr算子。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929104240226.png" alt="image-20190929104240226" style="zoom: 50%;" /></p>
</li>
<li><p>基于零穿越：通过寻找图像二阶导数零穿越来寻找边界，代表算法是Laplacian算子。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929104430480.png" alt="image-20190929104430480" style="zoom:67%;" /></p>
</li>
</ul>
<h4 id="Sobel算子"><a href="#Sobel算子" class="headerlink" title="Sobel算子"></a>Sobel算子</h4><p>Sobel边缘检测算法比较简单，实际应用中效率比canny边缘检测效率要高，但是边缘不如Canny检测的准确，但是很多实际应用的场合，sobel边缘却是首选，Sobel算子是高斯平滑与微分操作的结合体，所以其抗噪声能力很强，用途较多。尤其是效率要求较高，而对细纹理不太关心的时候。</p>
<p>对于不连续的函数，一阶导数可以写作：$f^′(x)=f(x)−f(x−1)$ 或 $f^′(x)=f(x+1)−f(x)$，所以有：</p>
<script type="math/tex; mode=display">
f^′(x)=\frac{f(x+1)−f(x−1)}{2}</script><p>假设要处理的图像为$I$，在两个方向求导：</p>
<ul>
<li><p><strong>水平变化</strong>：将图像$I$与奇数大小的模版进行卷积，结果为$G_x$。比如，当模板大小为3时，$G_x$为：</p>
<script type="math/tex; mode=display">
G_x=\begin{bmatrix} -1&0&+1 \\ -2&0&+2 \\ -1&0&+1 \end{bmatrix}*I</script></li>
<li><p><strong>垂直变化</strong>：将图像$I$与奇数大小的模板进行卷积，结果为$G_y$。比如，当模板大小为3时, $G_y$为：</p>
<script type="math/tex; mode=display">
G_y=\begin{bmatrix} -1&-2&-1 \\ 0&0&0 \\ +1&+2&+1 \end{bmatrix}*I</script></li>
</ul>
<p>在图像的每一点，结合以上两个结果求出：$G=\sqrt{G_x^2+G_y^2}$ ，统计极大值所在的位置，就是图像的边缘。</p>
<p><strong>注意</strong>：当内核大小为3时, 以上Sobel内核可能产生比较明显的误差， 为解决这一问题，我们使用Scharr函数，但该函数仅作用于大小为3的内核。该函数的运算与Sobel函数一样快，但结果却更加精确，其计算方法为：</p>
<script type="math/tex; mode=display">
G_x=\begin{bmatrix} -3&0&+3 \\ -10&0&+10 \\ -3&0&+3 \end{bmatrix}*I
\\
G_y=\begin{bmatrix} -3&-10&-3 \\ 0&0&0 \\ +3&+10&+3 \end{bmatrix}*I</script><p>利用OpenCV进行sobel边缘检测的API是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sobel_x_or_y = cv2.Sobel(src, ddepth, dx, dy, dst, ksize, scale, delta, borderType)</span><br></pre></td></tr></table></figure>
<ul>
<li>src：传入的图像</li>
<li>ddepth: 图像的深度</li>
<li>dx和dy: 指求导的阶数，0表示这个方向上没有求导，取值为0、1。</li>
<li>ksize: 是Sobel算子的大小，即卷积核的大小，必须为奇数1、3、5、7，默认为3（注意：如果ksize=-1，就演变成为3x3的Scharr算子）</li>
<li>scale：缩放导数的比例常数，默认情况为没有伸缩系数。</li>
<li>borderType：图像边界的模式，默认值为cv2.BORDER_DEFAULT。</li>
</ul>
<p>Sobel函数求完导数后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，所以Sobel建立的图像位数不够，会有截断。因此要使用16位有符号的数据类型，即cv2.CV_16S。处理完图像后，再使用cv2.convertScaleAbs()函数将其转回原来的uint8格式，否则图像无法显示。</p>
<p>Sobel算子是在两个方向计算的，最后还需要用cv2.addWeighted( )函数将其组合起来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Scale_abs = cv2.convertScaleAbs(x)  <span class="comment"># 格式转换函数</span></span><br><span class="line">result = cv2.addWeighted(src1, alpha, src2, beta) <span class="comment"># 图像混合</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/horse.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 2 计算Sobel卷积结果</span></span><br><span class="line">x = cv.Sobel(img, cv.CV_16S, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">y = cv.Sobel(img, cv.CV_16S, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 3 将数据进行转换</span></span><br><span class="line">Scale_absX = cv.convertScaleAbs(x)  <span class="comment"># convert 转换  scale 缩放</span></span><br><span class="line">Scale_absY = cv.convertScaleAbs(y)</span><br><span class="line"><span class="comment"># 4 结果合成</span></span><br><span class="line">result = cv.addWeighted(Scale_absX, <span class="number">0.5</span>, Scale_absY, <span class="number">0.5</span>, <span class="number">0</span>)</span><br><span class="line"><span class="comment"># 5 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img,cmap=plt.cm.gray),plt.title(<span class="string">&#x27;原图&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(result,cmap = plt.cm.gray),plt.title(<span class="string">&#x27;Sobel滤波后结果&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929141752847.png" alt="image-20190929141752847" style="zoom: 50%;" /></p>
<p>将上述代码中计算sobel算子的部分中将ksize设为-1，就是利用Scharr进行边缘检测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = cv.Sobel(img, cv.CV_16S, <span class="number">1</span>, <span class="number">0</span>, ksize = -<span class="number">1</span>)</span><br><span class="line">y = cv.Sobel(img, cv.CV_16S, <span class="number">0</span>, <span class="number">1</span>, ksize = -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929141636521.png" alt="image-20190929141636521" style="zoom: 50%;" /></p>
<h4 id="Laplacian算子"><a href="#Laplacian算子" class="headerlink" title="Laplacian算子"></a>Laplacian算子</h4><p>Laplacian是利用二阶导数来检测边缘 。 因为图像是 “2维”, 我们需要在两个方向求导，如下式所示：</p>
<script type="math/tex; mode=display">
Δsrc=\frac{∂^2src}{∂^2x}+\frac{∂^2src}{∂^2y}</script><p>那不连续函数的二阶导数是：</p>
<script type="math/tex; mode=display">
f^{′′}(x)=f^′(x+1)−f^′(x)=f(x+1)+f(x−1)−2f(x)</script><p>那使用的卷积核是：</p>
<script type="math/tex; mode=display">
kernel=\begin{bmatrix} 0&1&0 \\ 1&-4&1 \\ 0&1&0 \end{bmatrix}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">laplacian = cv2.Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]])</span><br></pre></td></tr></table></figure>
<ul>
<li>Src: 需要处理的图像，</li>
<li>Ddepth: 图像的深度，-1表示采用的是原图像相同的深度，目标图像的深度必须大于等于原图像的深度；</li>
<li>ksize：算子的大小，即卷积核的大小，必须为1,3,5,7。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/horse.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 2 laplacian转换</span></span><br><span class="line">result = cv.Laplacian(img,cv.CV_16S)</span><br><span class="line">Scale_abs = cv.convertScaleAbs(result)</span><br><span class="line"><span class="comment"># 3 图像展示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img,cmap=plt.cm.gray),plt.title(<span class="string">&#x27;原图&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(Scale_abs,cmap = plt.cm.gray),plt.title(<span class="string">&#x27;Laplacian检测后结果&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929145507862.png" alt="image-20190929145507862" style="zoom: 50%;" /></p>
<h4 id="Canny算子"><a href="#Canny算子" class="headerlink" title="Canny算子"></a>Canny算子</h4><p>Canny边缘检测算法是一种非常流行的边缘检测算法，是 John F. Canny 于 1986年提出的，被认为是最优的边缘检测算法。</p>
<p>Canny边缘检测算法是由4步构成，分别介绍如下：</p>
<ul>
<li><p><strong>第一步：噪声去除</strong></p>
<p>由于边缘检测很容易受到噪声的影响，所以首先使用$5*5$高斯滤波器去除噪声，在图像平滑那一章节中已经介绍过。</p>
</li>
<li><p><strong>第二步：计算图像梯度</strong></p>
<p>对平滑后的图像使用 Sobel 算子计算水平方向和竖直方向的一阶导数（Gx 和 Gy）。根据得到的这两幅梯度图（Gx 和 Gy）找到边界的梯度和方向，公式如下:</p>
<script type="math/tex; mode=display">
Edge\_Gradient(G)=\sqrt{G_x^2+G_y^2}
\\
Angle(\theta)=tan^{-1}(\frac{G_y}{G_x})</script><p>如果某个像素点是边缘，则其梯度方向总是垂直与边缘垂直。梯度方向被归为四类：垂直，水平，和两个对角线方向。</p>
</li>
<li><p><strong>第三步：非极大值抑制</strong></p>
<p>在获得梯度的方向和大小之后，对整幅图像进行扫描，去除那些非边界上的点。对每一个像素进行检查，看这个点的梯度是不是周围具有相同梯度方向的点中最大的。如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929153926063.png" alt="image-20190929153926063" style="zoom: 80%;" /></p>
<p>A点位于图像的边缘，在其梯度变化方向，选择像素点B和C，用来检验A点的梯度是否为极大值，若为极大值，则进行保留，否则A点被抑制，最终的结果是具有“细边”的二进制图像。</p>
</li>
<li><p><strong>第四步：滞后阈值</strong></p>
<p>现在要确定真正的边界。 我们设置两个阈值： minVal 和 maxVal。 当图像的灰度梯度高于 maxVal 时被认为是真的边界， 低于 minVal 的边界会被抛弃。如果介于两者之间的话，就要看这个点是否与某个被确定为真正的边界点相连，如果是就认为它也是边界点，如果不是就抛弃。如下图：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929155208751.png" alt="image-20190929155208751" style="zoom:67%;" /></p>
<p>如上图所示，A 高于阈值 maxVal 所以是真正的边界点，C 虽然低于 maxVal 但高于 minVal 并且与 A 相连，所以也被认为是真正的边界点。而 B 就会被抛弃，因为低于 maxVal 而且不与真正的边界点相连。所以选择合适的 maxVal 和 minVal 对于能否得到好的结果非常重要。</p>
</li>
</ul>
<p>在OpenCV中要实现Canny检测使用的API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">canny = cv2.Canny(image, threshold1, threshold2)</span><br></pre></td></tr></table></figure>
<ul>
<li>image:灰度图，</li>
<li>threshold1: minval，较小的阈值将间断的边缘连接起来</li>
<li>threshold2: maxval，较大的阈值检测图像中明显的边缘</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像读取</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/horse.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 2 Canny边缘检测</span></span><br><span class="line">lowThreshold = <span class="number">0</span></span><br><span class="line">max_lowThreshold = <span class="number">100</span></span><br><span class="line">canny = cv.Canny(img, lowThreshold, max_lowThreshold) </span><br><span class="line"><span class="comment"># 3 图像展示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img,cmap=plt.cm.gray),plt.title(<span class="string">&#x27;原图&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(canny,cmap = plt.cm.gray),plt.title(<span class="string">&#x27;Canny检测后结果&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20190929160959357.png" alt="image-20190929160959357" style="zoom: 50%;" /></p>
<h4 id="算子比较"><a href="#算子比较" class="headerlink" title="算子比较"></a>算子比较</h4><p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191024180930270.png" alt="image-20191024180930270" style="zoom: 50%;" /></p>
<h3 id="模版匹配"><a href="#模版匹配" class="headerlink" title="模版匹配"></a>模版匹配</h3><p>所谓的模板匹配，就是在给定的图片中查找和模板最相似的区域，该算法的输入包括模板和图片，整个任务的思路就是按照滑窗的思路不断的移动模板图片，计算其与图像中对应区域的匹配度，最终将匹配度最高的区域选择为最终的结果。</p>
<p><strong>实现流程：</strong></p>
<ul>
<li><p>准备两幅图像：</p>
<p>1.原图像(I)：在这幅图中，找到与模板相匹配的区域</p>
<p>2.模板(T)：与原图像进行比对的图像块</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Template_Matching_Template_Theory_Summary.jpg" alt="Template_Matching_Template_Theory_Summary" style="zoom:80%;" /></p>
</li>
<li><p>滑动模板图像和原图像进行比对：将模板块每次移动一个像素 (从左往右，从上往下)，在每一个位置，都计算与模板图像的相似程度。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Template_Matching_Template_Theory_Sliding.jpg" alt="Template_Matching_Template_Theory_Sliding" style="zoom:80%;" /></p>
</li>
<li><p>对于每一个位置将计算的相似结果保存在结果矩阵（R）中。如果输入图像的大小（WxH）且模板图像的大小(wxh)，则输出矩阵R的大小为（W-w+1, H-h+1）将R显示为图像，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/Template_Matching_Template_Theory_Result.jpg" alt="Template_Matching_Template_Theory_Result" style="zoom:80%;" /></p>
</li>
<li><p>获得上述图像后，查找最大值所在的位置，那么该位置对应的区域就被认为是最匹配的。对应的区域就是以该点为顶点，长宽和模板图像一样大小的矩阵。</p>
</li>
</ul>
<p>我们使用OpenCV中的方法实现模板匹配。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res = cv.matchTemplate(img,template,method)</span><br></pre></td></tr></table></figure>
<ul>
<li>img: 要进行模板匹配的图像</li>
<li>Template ：模板</li>
<li>method：实现模板匹配的算法，主要有：<ol>
<li>平方差匹配(CV_TM_SQDIFF)：利用模板与图像之间的平方差进行匹配，最好的匹配是0，匹配越差，匹配的值越大。</li>
<li>相关匹配(CV_TM_CCORR)：利用模板与图像间的乘法进行匹配，数值越大表示匹配程度较高，越小表示匹配效果差。</li>
<li>利用相关系数匹配(CV_TM_CCOEFF)：利用模板与图像间的相关系数匹配，1表示完美的匹配，-1表示最差的匹配。</li>
</ol>
</li>
</ul>
<p>完成匹配后，使用cv.minMaxLoc()方法查找最大值所在的位置即可。如果使用平方差作为比较方法，则最小值位置是最佳匹配位置。</p>
<p><strong>示例：</strong></p>
<p>在该案例中，载入要搜索的图像和模板，图像如下所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/wulin2.jpeg" alt="wulin2" style="zoom: 80%;" /></p>
<p>模板如下所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/wulin-0430810.jpeg" alt="wulin-0430810"></p>
<p>通过matchTemplate实现模板匹配，使用minMaxLoc定位最匹配的区域，并用矩形标注最匹配的区域。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像和模板读取</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/wulin2.jpeg&#x27;</span>)</span><br><span class="line">template = cv.imread(<span class="string">&#x27;./image/wulin.jpeg&#x27;</span>)</span><br><span class="line">h,w,l = template.shape</span><br><span class="line"><span class="comment"># 2 模板匹配</span></span><br><span class="line"><span class="comment"># 2.1 模板匹配</span></span><br><span class="line">res = cv.matchTemplate(img, template, cv.TM_CCORR)</span><br><span class="line"><span class="comment"># 2.2 返回图像中最匹配的位置，确定左上角的坐标，并将匹配位置绘制在图像上</span></span><br><span class="line">min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)</span><br><span class="line"><span class="comment"># 使用平方差时最小值为最佳匹配位置</span></span><br><span class="line"><span class="comment"># top_left = min_loc</span></span><br><span class="line">top_left = max_loc</span><br><span class="line">bottom_right = (top_left[<span class="number">0</span>] + w, top_left[<span class="number">1</span>] + h)</span><br><span class="line">cv.rectangle(img, top_left, bottom_right, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;匹配结果&#x27;</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007144614688.png" alt="image-20191007144614688" style="zoom:80%;" /></p>
<p>拓展：模板匹配不适用于尺度变换，视角变换后的图像，这时我们就要使用关键点匹配算法，比较经典的关键点检测算法包括SIFT和SURF等，主要的思路是首先通过关键点检测算法获取模板和测试图片中的关键点；然后使用关键点匹配算法处理即可，这些关键点可以很好的处理尺度变化、视角变换、旋转变化、光照变化等，具有很好的不变性。</p>
<h3 id="霍夫变换"><a href="#霍夫变换" class="headerlink" title="霍夫变换"></a>霍夫变换</h3><h4 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a>原理介绍</h4><p>霍夫变换常用来提取图像中的直线和圆等几何形状，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007151122386.png" alt="image-20191007151122386" style="zoom: 50%;" /></p>
<p>在笛卡尔坐标系中，一条直线由两个$A=(x_1,y_1)$和$B=(x_2,y_2)$确定，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007153126537.png" alt="image-20191007153126537"></p>
<p>将直线$y=kx+q$可写成关于$(k,q)$的函数表达式：</p>
<script type="math/tex; mode=display">
\begin{cases}
q=-kx_1+y_1 \\ q = -kx_2+y_2
\end{cases}</script><p>对应的变换通过图形直观的表示下：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007154123721.png" alt="image-20191007154123721" style="zoom:80%;" /></p>
<p>变换后的空间我们叫做霍夫空间。即：<strong>笛卡尔坐标系中的一条直线，对应于霍夫空间中的一个点</strong>。反过来，同样成立，霍夫空间中的一条线，对应于笛卡尔坐标系中一个点，如下所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007154350195.png" alt="image-20191007154350195" style="zoom: 80%;" /></p>
<p>​    我们再来看下A、B两个点，对应于霍夫空间的情形：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007154546905.png" alt="image-20191007154546905" style="zoom: 80%;" /></p>
<p>在看下三点共线的情况：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007160434136.png" alt="image-20191007160434136" style="zoom: 67%;" /></p>
<p>可以看出如果<strong>在笛卡尔坐标系的点共线，那么这些点在霍夫空间中对应的直线交于一点</strong>。</p>
<p>如果不止存在一条直线时，如下所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007160932077.png" alt="image-20191007160932077" style="zoom:67%;" /></p>
<p>我们选择尽可能多的直线汇成的点，上图中三条直线汇成的A、B两点，将其对应回笛卡尔坐标系中的直线：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007161219204.png" alt="image-20191007161219204" style="zoom:67%;" /></p>
<p>到这里我们似乎已经完成了霍夫变换的求解。但如果像下图这种情况时：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007161417485.png" alt="image-20191007161417485" style="zoom:80%;" /></p>
<p>上图中的直线是$x=2$，那$(k,q)$怎么确定呢？</p>
<p>为了解决这个问题，我们考虑将笛卡尔坐标系转换为极坐标。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007165431682.png" alt="image-20191007165431682" style="zoom: 67%;" /></p>
<p>在极坐标下是一样的，极坐标中的点对应于霍夫空间的线，这时的霍夫空间是不在是参数$(k,q)$的空间，而是$(ρ,θ)$的空间，$ρ$是原点到直线的垂直距离，$θ$表示直线的垂线与横轴顺时针方向的夹角，垂直线的角度为0度，水平线的角度是180度。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007163203594.png" alt="image-20191007163203594" style="zoom: 67%;" /></p>
<p>我们只要求得霍夫空间中的交点的位置，即可得到原坐标系下的直线。</p>
<p>假设有一个大小为$100∗100$的图片，使用霍夫变换检测图片中的直线，则步骤如下所示：</p>
<ul>
<li><p>直线都可以使用$(ρ,θ)$表示，首先创建一个2D数组，我们叫做<strong>累加器</strong>，初始化所有值为0，行表示$ρ$ ，列表示$θ$ 。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007170330026.png" alt="image-20191007170330026" style="zoom:80%;" /></p>
<p>该数组的大小决定了结果的准确性，若希望角度的精度为1度，那就需要180列。对于$ρ$，最大值为图片对角线的距离，如果希望精度达到像素级别，行数应该与图像的对角线的距离相等。</p>
</li>
<li><p>取直线上的第一个点$(x,y)$，将其带入直线在极坐标中的公式中，然后遍历$θ$的取值：0，1，2，…，180，分别求出对应的$ρ$值，如果这个数值在上述累加器中存在相应的位置，则在该位置上加1</p>
</li>
<li><p>取直线上的第二个点，重复上述步骤，更新累加器中的值。对图像中的直线上的每个点都直线以上步骤，每次更新累加器中的值。</p>
</li>
<li><p>搜索累加器中的最大值，并找到其对应的$(ρ,θ)$，就可将图像中的直线表示出来。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image70-0440438.gif" alt="image70-0440438"></p>
</li>
</ul>
<h4 id="霍夫线检测"><a href="#霍夫线检测" class="headerlink" title="霍夫线检测"></a>霍夫线检测</h4><p>在OpenCV中做霍夫线检测是使用的API是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.HoughLines(img, rho, theta, threshold)</span><br></pre></td></tr></table></figure>
<ul>
<li>img: 检测的图像，要求是二值化的图像，所以在调用霍夫变换之前首先要进行二值化，或者进行Canny边缘检测</li>
<li>rho、theta: $ρ$ 和 $θ$ 的精确度</li>
<li>threshold: 阈值，只有累加器中的值高于该阈值时才被认为是直线。</li>
</ul>
<p>霍夫线检测的整个流程如下图所示，这是在stackflow上一个关于霍夫线变换的解释：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007184838549.png" alt="image-20191007184838549" style="zoom:67%;" /></p>
<p><strong>示例：</strong>检测下述图像中的直线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1.加载图片，转为二值图</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/rili.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line">edges = cv.Canny(gray, <span class="number">50</span>, <span class="number">150</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.霍夫直线变换</span></span><br><span class="line">lines = cv.HoughLines(edges, <span class="number">0.8</span>, np.pi / <span class="number">180</span>, <span class="number">150</span>)</span><br><span class="line"><span class="comment"># 3.将检测的线绘制在图像上（注意是极坐标噢）</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    rho, theta = line[<span class="number">0</span>]</span><br><span class="line">    a = np.cos(theta)</span><br><span class="line">    b = np.sin(theta)</span><br><span class="line">    x0 = a * rho</span><br><span class="line">    y0 = b * rho</span><br><span class="line">    x1 = <span class="built_in">int</span>(x0 + <span class="number">1000</span> * (-b))</span><br><span class="line">    y1 = <span class="built_in">int</span>(y0 + <span class="number">1000</span> * (a))</span><br><span class="line">    x2 = <span class="built_in">int</span>(x0 - <span class="number">1000</span> * (-b))</span><br><span class="line">    y2 = <span class="built_in">int</span>(y0 - <span class="number">1000</span> * (a))</span><br><span class="line">    cv.line(img, (x1, y1), (x2, y2), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>))</span><br><span class="line"><span class="comment"># 4. 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;霍夫变换线检测&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<table><tr>
<td><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/rili.jpg" border=0></td>
<td><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191007184301611.png" style="zoom: 30%;" border=0></td>
</tr></table>

<h4 id="霍夫圆检测"><a href="#霍夫圆检测" class="headerlink" title="霍夫圆检测"></a>霍夫圆检测</h4><p>圆的表示式是：$(x−a)^2+(y−b)^2=r$其中$a$和$b$表示圆心坐标，$r$表示圆半径，因此标准的霍夫圆检测就是在这三个参数组成的三维空间累加器上进行圆形检测，此时效率就会很低，所以OpenCV中使用<strong>霍夫梯度法</strong>进行圆形的检测。</p>
<p>霍夫梯度法将霍夫圆检测范围两个阶段，第一阶段检测圆心，第二阶段利用圆心推导出圆半径。</p>
<ul>
<li>圆心检测的原理：圆心是圆周法线的交汇处，设置一个阈值，在某点的相交的直线的条数大于这个阈值就认为该交汇点为圆心。</li>
<li>圆半径确定原理：圆心到圆周上的距离（半径）是相同的，确定一个阈值，只要相同距离的数量大于该阈值，就认为该距离是该圆心的半径。</li>
</ul>
<p>原则上霍夫变换可以检测任何形状，但复杂的形状需要的参数就多，霍夫空间的维数就多，因此在程序实现上所需的内存空间以及运行效率上都不利于把标准霍夫变换应用于实际复杂图形的检测中。霍夫梯度法是霍夫变换的改进，它的目的是减小霍夫空间的维度，提高效率。</p>
<p>在OpenCV中检测图像中的圆环使用的是API是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">circles = cv.HoughCircles(image, method, dp, minDist, param1=<span class="number">100</span>, param2=<span class="number">100</span>, minRadius=<span class="number">0</span>,maxRadius=<span class="number">0</span> )</span><br></pre></td></tr></table></figure>
<ul>
<li>image：输入图像，应输入灰度图像</li>
<li>method：使用霍夫变换圆检测的算法，它的参数是CV_HOUGH_GRADIENT</li>
<li>dp：霍夫空间的分辨率，dp=1时表示霍夫空间与输入图像空间的大小一致，dp=2时霍夫空间是输入图像空间的一半，以此类推</li>
<li>minDist为圆心之间的最小距离，如果检测到的两个圆心之间距离小于该值，则认为它们是同一个圆心</li>
<li>param1：边缘检测时使用Canny算子的高阈值，低阈值是高阈值的一半。</li>
<li>param2：检测圆心和确定半径时所共有的阈值</li>
<li><p>minRadius和maxRadius为所检测到的圆半径的最小值和最大值</p>
</li>
<li><p>返回值circles：输出圆向量，包括三个浮点型的元素——圆心横坐标，圆心纵坐标和圆半径</p>
</li>
</ul>
<p>由于霍夫圆检测对噪声比较敏感，所以首先对图像进行中值滤波：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像，并转换为灰度图</span></span><br><span class="line">planets = cv.imread(<span class="string">&quot;./image/star.jpeg&quot;</span>)</span><br><span class="line">gay_img = cv.cvtColor(planets, cv.COLOR_BGRA2GRAY)</span><br><span class="line"><span class="comment"># 2 进行中值模糊，去噪点</span></span><br><span class="line">img = cv.medianBlur(gay_img, <span class="number">7</span>)  </span><br><span class="line"><span class="comment"># 3 霍夫圆检测</span></span><br><span class="line">circles = cv.HoughCircles(img, cv.HOUGH_GRADIENT, <span class="number">1</span>, <span class="number">200</span>, param1=<span class="number">100</span>, param2=<span class="number">30</span>, minRadius=<span class="number">0</span>, maxRadius=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 4 将检测结果绘制在图像上</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> circles[<span class="number">0</span>, :]:  <span class="comment"># 遍历矩阵每一行的数据</span></span><br><span class="line">    <span class="comment"># 绘制圆形</span></span><br><span class="line">    cv.circle(planets, (i[<span class="number">0</span>], i[<span class="number">1</span>]), i[<span class="number">2</span>], (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 绘制圆心</span></span><br><span class="line">    cv.circle(planets, (i[<span class="number">0</span>], i[<span class="number">1</span>]), <span class="number">2</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 5 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(planets[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;霍夫变换圆检测&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008105125382.png" alt="image-20191008105125382" style="zoom: 50%;" /></p>
<h2 id="图像特征提取与描述"><a href="#图像特征提取与描述" class="headerlink" title="图像特征提取与描述"></a>图像特征提取与描述</h2><ul>
<li>图像的特征</li>
<li>Harris和Shi-Tomasi算法的原理及角点检测的实现</li>
<li>SIFT/SURF算法的原理及使用SIFT/SURF进行关键点的检测方法</li>
<li>Fast算法角点检测的原理角及其应用</li>
<li>ORB算法的原理，及特征点检测的实现</li>
</ul>
<h3 id="角点特征"><a href="#角点特征" class="headerlink" title="角点特征"></a>角点特征</h3><p>大多数人都玩过拼图游戏。首先拿到完整图像的碎片，然后把这些碎片以正确的方式排列起来从而重建这幅图像。如果把拼图游戏的原理写成计算机程序，那计算机就也会玩拼图游戏了。</p>
<p>在拼图时，我们要寻找一些唯一的特征，这些特征要适于被跟踪，容易被比较。我们在一副图像中搜索这样的特征，找到它们，而且也能在其他图像中找到这些特征，然后再把它们拼接到一起。我们的这些能力都是天生的。</p>
<p>那这些特征是什么呢？我们希望这些特征也能被计算机理解。</p>
<p>如果我们深入的观察一些图像并搜索不同的区域，以下图为例：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008141826875.png" alt="image-20191008141826875" style="zoom:80%;" /></p>
<p>在图像的上方给出了六个小图。找到这些小图在原始图像中的位置。你能找到多少正确结果呢？</p>
<p>A 和 B 是平面，而且它们的图像中很多地方都存在。很难找到这些小图的准确位置。</p>
<p>C 和 D 也很简单。它们是建筑的边缘。可以找到它们的近似位置，但是准确位置还是很难找到。这是因为：沿着边缘，所有的地方都一样。所以边缘是比平面更好的特征，但是还不够好。</p>
<p>最后 E 和 F 是建筑的一些角点。它们能很容易的被找到。因为在角点的地方，无论你向哪个方向移动小图，结果都会有很大的不同。所以可以把它们当 成一个好的特征。为了更好的理解这个概念我们再举个更简单的例子。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008141945745.png" alt="image-20191008141945745" style="zoom:80%;" /></p>
<p>如上图所示，蓝色框中的区域是一个平面很难被找到和跟踪。无论向哪个方向移动蓝色框，都是一样的。对于黑色框中的区域，它是一个边缘。如果沿垂直方向移动，它会改变。但是如果沿水平方向移动就不会改变。而红色框中的角点，无论你向那个方向移动，得到的结果都不同，这说明它是唯一的。 所以，我们说角点是一个好的图像特征，也就回答了前面的问题。</p>
<p>角点是图像很重要的特征,对图像图形的理解和分析有很重要的作用。角点在三维场景重建运动估计，目标跟踪、目标识别、图像配准与匹配等计算机视觉领域起着非常重要的作用。在现实世界中，角点对应于物体的拐角，道路的十字路口、丁字路口等</p>
<p>那我们怎样找到这些角点呢？接下来我们使用 OpenCV 中的各种算法来查找图像的特征，并对它们进行描述。</p>
<h3 id="Harris算法"><a href="#Harris算法" class="headerlink" title="Harris算法"></a>Harris算法</h3><p>Harris角点检测的思想是通过图像的局部的小窗口观察图像，角点的特征是窗口沿任意方向移动都会导致图像灰度的明显变化，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008144647540.png" alt="image-20191008144647540" style="zoom: 50%;" /></p>
<p>将上述思想转换为数学形式，即将局部窗口向各个方向移动$(u,v)$并计算所有灰度差异的总和，表达式如下：</p>
<script type="math/tex; mode=display">
E(u,v)=\sum_{x,y}w(x,y)[I(x+u,y+v)−I(x,y)]^2</script><p>其中$I(x,y)$是局部窗口的图像灰度，$I(x+u,y+v)$是平移后的图像灰度，$w(x,y)$是窗口函数，该可以是矩形窗口，也可以是对每一个像素赋予不同权重的高斯窗口，如下所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008153014984.png" alt="image-20191008153014984" style="zoom: 50%;" /></p>
<p>角点检测中使$E(u,v)$的值最大。利用一阶泰勒展开有：</p>
<script type="math/tex; mode=display">
I(x+u,y+v)=I(x,y)+I_xu+I_yv</script><p>其中$I_x$和 $I_y$ 是沿$x$和$y$方向的导数，可用sobel算子计算。</p>
<p>推导如下：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191015180016665.png" alt="image-20191015180016665" style="zoom:67%;" /></p>
<p>$M$矩阵决定了$E(u,v)$的取值，下面我们利用$M$来求角点，$M$是$I_x$和$I_y$的二次项函数，可以表示成椭圆的形状，椭圆的长短半轴由$M$的特征值$λ_1$和$λ_2$决定，方向由特征矢量决定，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008160908338.png" alt="image-20191008160908338" style="zoom: 67%;" /></p>
<p>椭圆函数特征值与图像中的角点、直线（边缘）和平面之间的关系如下图所示。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008161040473.png" alt="image-20191008161040473" style="zoom: 60%;" /></p>
<p>共可分为三种情况：</p>
<ul>
<li>图像中的直线。一个特征值大，另一个特征值小，$λ1&gt;&gt;λ2$或 $λ2&gt;&gt;λ1$。椭圆函数值在某一方向上大，在其他方向上小。</li>
<li>图像中的平面。两个特征值都小，且近似相等；椭圆函数数值在各个方向上都小。</li>
<li>图像中的角点。两个特征值都大，且近似相等，椭圆函数在所有方向都增大。</li>
</ul>
<p>Harris给出的角点计算方法并不需要计算具体的特征值，而是计算一个<strong>角点响应值R</strong>来判断角点。$R$的计算公式为：</p>
<script type="math/tex; mode=display">
R=detM−α(traceM)^2</script><p>式中，$detM$为矩阵$M$的行列式；$traceM$为矩阵$M$的迹；$α$为常数，取值范围为0.04~0.06。事实上，特征是隐含在$detM$和$traceM$中，因为：</p>
<script type="math/tex; mode=display">
detM=\lambda_1 \lambda_2 \\
traceM=\lambda_1 + \lambda_2</script><p>那我们怎么判断角点呢？如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008161904372.png" alt="image-20191008161904372" style="zoom:50%;" /></p>
<ul>
<li>当R为大数值的正数时是角点</li>
<li>当R为大数值的负数时是边界</li>
<li>当R为小数是认为是平坦区域</li>
</ul>
<p>在OpenCV中实现Hariis检测使用的API是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dst=cv.cornerHarris(src, blockSize, ksize, k)</span><br></pre></td></tr></table></figure>
<ul>
<li>img：数据类型为 ﬂoat32 的输入图像。</li>
<li>blockSize：角点检测中要考虑的邻域大小。</li>
<li>ksize：sobel求导使用的核大小</li>
<li>k ：角点检测方程中的自由参数，取值参数为 [0.04，0.06].</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像，并转换成灰度图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/chessboard.jpg&#x27;</span>)</span><br><span class="line">gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 2 角点检测</span></span><br><span class="line"><span class="comment"># 2.1 输入图像必须是 float32</span></span><br><span class="line">gray = np.float32(gray)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 最后一个参数在 0.04 到 0.05 之间</span></span><br><span class="line">dst = cv.cornerHarris(gray,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0.04</span>)</span><br><span class="line"><span class="comment"># 3 设置阈值，将角点绘制出来，阈值根据图像进行选择</span></span><br><span class="line">img[dst&gt;<span class="number">0.001</span>*dst.<span class="built_in">max</span>()] = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]</span><br><span class="line"><span class="comment"># 4 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;Harris角点检测&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008164344988.png" alt="image-20191008164344988" style="zoom: 33%;" /></p>
<p>Harris角点检测的优缺点：</p>
<p>优点：</p>
<ul>
<li>旋转不变性，椭圆转过一定角度但是其形状保持不变（特征值保持不变）</li>
<li>对于图像灰度的仿射变化具有部分的不变性，由于仅仅使用了图像的一介导数，对于图像灰度平移变化不变；对于图像灰度尺度变化不变</li>
</ul>
<p>缺点：</p>
<ul>
<li>对尺度很敏感，不具备几何尺度不变性。</li>
<li>提取的角点是像素级的</li>
</ul>
<h3 id="Shi-Tomasi算法"><a href="#Shi-Tomasi算法" class="headerlink" title="Shi-Tomasi算法"></a>Shi-Tomasi算法</h3><p>Shi-Tomasi算法是对Harris角点检测算法的改进，一般会比Harris算法得到更好的角点。Harris 算法的角点响应函数是将矩阵 M 的行列式值与 M 的迹相减，利用差值判断是否为角点。后来Shi 和Tomasi 提出改进的方法是，若矩阵M的两个特征值中较小的一个大于阈值，则认为他是角点，即：</p>
<script type="math/tex; mode=display">
R=min(λ_1,λ_2)</script><p>如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008171309192.png" alt="image-20191008171309192"></p>
<p>从这幅图中，可以看出来只有当$λ_1$和$λ_2$都大于最小值时，才被认为是角点。</p>
<p>在OpenCV中实现Shi-Tomasi角点检测使用API:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">corners = cv2.goodFeaturesToTrack (image, maxcorners, qualityLevel, minDistance )</span><br></pre></td></tr></table></figure>
<ul>
<li>Image: 输入灰度图像</li>
<li>maxCorners : 获取角点数的数目。</li>
<li>qualityLevel：该参数指出最低可接受的角点质量水平，在0-1之间。</li>
<li>minDistance：角点之间最小的欧式距离，避免得到相邻特征点。</li>
<li>返回值：Corners: 搜索到的角点，在这里所有低于质量水平的角点被排除掉，然后把合格的角点按质量排序，然后将质量较好的角点附近（小于最小欧式距离）的角点删掉，最后找到maxCorners个角点返回。</li>
</ul>
<p><strong>示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/tv.jpg&#x27;</span>) </span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 2 角点检测</span></span><br><span class="line">corners = cv.goodFeaturesToTrack(gray,<span class="number">1000</span>,<span class="number">0.01</span>,<span class="number">10</span>)  </span><br><span class="line"><span class="comment"># 3 绘制角点</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> corners:</span><br><span class="line">    x,y = i.ravel()</span><br><span class="line">    cv.circle(img,(x,y),<span class="number">2</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 4 图像展示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;shi-tomasi角点检测&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008174257711-167759358741034.png" alt="image-20191008174257711" style="zoom:50%;" /></p>
<h3 id="SIFT-SURF算法"><a href="#SIFT-SURF算法" class="headerlink" title="SIFT/SURF算法"></a>SIFT/SURF算法</h3><p>前面两节我们介绍了Harris和Shi-Tomasi角点检测算法，这两种算法具有旋转不变性，但不具有尺度不变性，以下图为例，在左侧小图中可以检测到角点，但是图像被放大后，在使用同样的窗口，就检测不到角点了。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191008181535222-167759455781036.png" alt="image-20191008181535222"></p>
<p>所以，下面我们来介绍一种计算机视觉的算法，尺度不变特征转换即SIFT (Scale-invariant feature transform)。它用来侦测与描述影像中的局部性特征，它在空间尺度中寻找极值点，并提取出其位置、尺度、旋转不变量，此算法由 David Lowe在1999年所发表，2004年完善总结。应用范围包含物体辨识、机器人地图感知与导航、影像缝合、3D模型建立、手势辨识、影像追踪和动作比对等领域。</p>
<p>SIFT算法的实质是在不同的尺度空间上查找关键点(特征点)，并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照，仿射变换和噪音等因素而变化的点，如<strong>角点、边缘点、暗区的亮点及亮区的暗点</strong>等。</p>
<p>Lowe将SIFT算法分解为如下<strong>四步</strong>：</p>
<ol>
<li>尺度空间极值检测：搜索所有尺度上的图像位置。通过高斯差分函数来识别潜在的对于尺度和旋转不变的关键点。</li>
<li>关键点定位：在每个候选的位置上，通过一个拟合精细的模型来确定位置和尺度。关键点的选择依据于它们的稳定程度。</li>
<li>关键点方向确定：基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而保证了对于这些变换的不变性。</li>
<li>关键点描述：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度作为关键点的描述符，它允许比较大的局部形状的变形或光照变化。</li>
</ol>
<p>我们就沿着Lowe的步骤，对SIFT算法的实现过程进行介绍：</p>
<h4 id="尺度空间极值检测"><a href="#尺度空间极值检测" class="headerlink" title="尺度空间极值检测"></a>尺度空间极值检测</h4><p>在不同的尺度空间是不能使用相同的窗口检测极值点，对小的关键点使用小的窗口，对大的关键点使用大的窗口，为了达到上述目的，我们使用尺度空间滤波器。</p>
<blockquote>
<p>高斯核是唯一可以产生多尺度空间的核函数。-《Scale-space theory: A basic tool for analysing structures at different scales》。</p>
</blockquote>
<p>一个图像的尺度空间$L(x,y,σ)$，定义为原始图像$I(x,y)$与一个可变尺度的2维高斯函数$G(x,y,σ)$卷积运算 ，即：</p>
<script type="math/tex; mode=display">
L(x,y,σ)=G(x,y,σ)∗I(x,y)</script><p>其中：</p>
<script type="math/tex; mode=display">
G(x,y,σ)=\frac{1}{2πσ^2}e^{−\frac{x^2+y^2}{2σ^2}}</script><p>$σ$是尺度空间因子，它决定了图像的模糊的程度。在大尺度下（$σ$值大）表现的是图像的概貌信息，在小尺度下（$σ$值小）表现的是图像的细节信息。</p>
<p>在计算高斯函数的离散近似时，在大概$3σ$距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。所以，在实际应用中，只计算$(6σ+1)*(6σ+1)$的高斯卷积核就可以保证相关像素影响。</p>
<p>下面我们构建图像的高斯金字塔，它采用高斯函数对图像进行模糊以及降采样处理得到的，高斯金字塔构建过程中，首先将图像扩大一倍，在扩大的图像的基础之上构建高斯金字塔，然后对该尺寸下图像进行高斯模糊，几幅模糊之后的图像集合构成了一个Octave，然后对该Octave下选择一幅图像进行下采样，长和宽分别缩短一倍，图像面积变为原来四分之一。这幅图像就是下一个Octave的初始图像，在初始图像的基础上完成属于这个Octave的高斯模糊处理，以此类推完成整个算法所需要的所有八度构建，这样这个高斯金字塔就构建出来了，整个流程如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009110944907-167759498591538.png" alt="image-20191009110944907" style="zoom:67%;" /></p>
<p>利用LoG(高斯拉普拉斯方法)，即图像的二阶导数，可以在不同的尺度下检测图像的关键点信息，从而确定图像的特征点。但LoG的计算量大，效率低。所以我们通过两个相邻高斯尺度空间的图像的相减，得到DoG(高斯差分)来近似LoG。</p>
<p>为了计算DoG我们构建高斯差分金字塔，该金字塔是在上述的高斯金字塔的基础上构建而成的，建立过程是：在高斯金字塔中每个Octave中相邻两层相减就构成了高斯差分金字塔。如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009113953721-167759506125740.png" alt="image-20191009113953721" style="zoom:67%;" /></p>
<p>高斯差分金字塔的第1组第1层是由高斯金字塔的第1组第2层减第1组第1层得到的。以此类推，逐组逐层生成每一个差分图像，所有差分图像构成差分金字塔。概括为DOG金字塔的第o组第l层图像是有高斯金字塔的第o组第l+1层减第o组第l层得到的。后续Sift特征点的提取都是在DOG金字塔上进行的</p>
<p>在 DoG 搞定之后，就可以在不同的尺度空间中搜索局部最大值了。对于图像中的一个像素点而言，它需要与自己周围的 8 邻域，以及尺度空间中上下两层中的相邻的 18（2x9）个点相比。如果是局部最大值，它就可能是一个关键点。基本上来说关键点是图像在相应尺度空间中的最好代表。如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009115023016-167759558757842.png" alt="image-20191009115023016" style="zoom:80%;" /></p>
<p>搜索过程从每组的第二层开始，以第二层为当前层，对第二层的DoG图像中的每个点取一个3×3的立方体，立方体上下层为第一层与第三层。这样，搜索得到的极值点既有位置坐标（DoG的图像坐标），又有空间尺度坐标（层坐标）。当第二层搜索完成后，再以第三层作为当前层，其过程与第二层的搜索类似。当$S=3$时，每组里面要搜索3层，所以在DOG中就有$S+2$层，在初使构建的金字塔中每组有$S+3$层。</p>
<h4 id="关键点定位"><a href="#关键点定位" class="headerlink" title="关键点定位"></a>关键点定位</h4><p>由于DoG对噪声和边缘比较敏感，因此在上面高斯差分金字塔中检测到的局部极值点需经过进一步的检验才能精确定位为特征点。</p>
<p>使用尺度空间的泰勒级数展开来获得极值的准确位置， 如果<strong>极值点的 灰度值小于阈值</strong>（一般为0.03或0.04）就会被忽略掉。 在 OpenCV 中这种阈值被称为 contrastThreshold。</p>
<p>DoG 算法对边界非常敏感， 所以我们必须要把边界去除。 Harris 算法除了可以用于角点检测之外还可以用于检测边界。从 Harris 角点检测的算法中，当一个特征值远远大于另外一个特征值时检测到的是边界。那在DoG算法中欠佳的关键点在平行边缘的方向有较大的主曲率，而在垂直于边缘的方向有较小的曲率，两者的比值如果高于某个阈值（在OpenCV中叫做边界阈值），就认为该关键点为边界，将被忽略，一般将该阈值设置为10。</p>
<p>将低对比度和边界的关键点去除，得到的就是我们感兴趣的关键点。</p>
<h4 id="关键点方向确定"><a href="#关键点方向确定" class="headerlink" title="关键点方向确定"></a>关键点方向确定</h4><p>经过上述两个步骤，图像的关键点就完全找到了，这些关键点具有尺度不变性。为了实现旋转不变性，还需要为每个关键点分配一个方向角度，也就是根据检测到的关键点所在高斯尺度图像的邻域结构中求得一个方向基准。</p>
<p>对于任一关键点，我们采集其所在高斯金字塔图像以$r$为半径的区域内所有像素的梯度特征（幅值和幅角），半径$r$为：$r=3×1.5σ$其中$σ$是关键点所在octave的图像的尺度，可以得到对应的尺度图像。</p>
<p>梯度的幅值和方向的计算公式为：</p>
<script type="math/tex; mode=display">
m(x,y)=\sqrt{(L(x+1,y)-L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2}
\\
θ(x,y)=arctan(\frac{L(x,y+1)−L(x,y−1)}{L(x+1,y)−L(x−1,y)})</script><p>邻域像素梯度的计算结果如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009143818527-167759743395844.png" alt="image-20191009143818527" style="zoom:67%;" /></p>
<p>完成关键点梯度计算后，使用直方图统计关键点邻域内像素的梯度幅值和方向。具体做法是，将360°分为36柱，每10°为一柱，然后在以r为半径的区域内，将梯度方向在某一个柱内的像素找出来，然后将他们的幅值相加在一起作为柱的高度。因为在r为半径的区域内像素的梯度幅值对中心像素的贡献是不同的，因此还需要对幅值进行加权处理，采用高斯加权，方差为$1.5σ$。如下图所示，为简化图中只画了8个方向的直方图。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009144726492-167759745931346.png" alt="image-20191009144726492" style="zoom: 50%;" /></p>
<p>每个特征点必须分配一个主方向，还需要一个或多个辅方向，增加辅方向的目的是为了增强图像匹配的鲁棒性。辅方向的定义是，当一个柱体的高度大于主方向柱体高度的80%时，则该柱体所代表的的方向就是给特征点的辅方向。</p>
<p>直方图的峰值，即最高的柱代表的方向是特征点邻域范围内图像梯度的主方向，但该柱体代表的角度是一个范围，所以我们还要对离散的直方图进行插值拟合，以得到更精确的方向角度值。利用抛物线对离散的直方图进行拟合，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009150008701-167759749637048.png" alt="image-20191009150008701" style="zoom:50%;" /></p>
<p>获得图像关键点主方向后，每个关键点有三个信息$(x,y,σ,θ)$：位置、尺度、方向。由此我们可以确定一个SIFT特征区域。通常使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置，半径表示关键点尺度，箭头表示方向。如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191025112522974-167759754642250.png" alt="image-20191025112522974" style="zoom: 67%;" /></p>
<h4 id="关键点描述"><a href="#关键点描述" class="headerlink" title="关键点描述"></a>关键点描述</h4><p>通过以上步骤，每个关键点就被分配了位置，尺度和方向信息。接下来我们为每个关键点建立一个描述符，该描述符既具有可区分性，又具有对某些变量的不变性，如光照，视角等。而且描述符不仅仅包含关键点，也包括关键点周围对其有贡献的的像素点。主要思路就是通过将关键点周围图像区域分块，计算块内的梯度直方图，生成具有特征向量，对图像信息进行抽象。</p>
<p>描述符与特征点所在的尺度有关，所以我们在关键点所在的高斯尺度图像上生成对应的描述符。以特征点为中心，将其附近邻域划分为$d∗d$个子区域（一般取$d=4$)，每个子区域都是一个正方形，边长为$3σ$，考虑到实际计算时，需进行三次线性插值，所以特征点邻域的为$3σ(d+1)∗3σ(d+1)$的范围，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009161647267-167759767449452.png" alt="image-20191009161647267" style="zoom:80%;" /></p>
<p>为了保证特征点的旋转不变性，以特征点为中心，将坐标轴旋转为关键点的主方向，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009161756423-167759774753954.png" alt="image-20191009161756423" style="zoom:67%;" /></p>
<p>计算子区域内的像素的梯度，并按照$σ=0.5d$进行高斯加权，然后插值计算得到每个种子点的八个方向的梯度，插值方法如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009162914982-167759777357556.png" alt="image-20191009162914982" style="zoom:67%;" /></p>
<p>每个种子点的梯度都是由覆盖其的4个子区域插值而得的。如图中的红色点，落在第0行和第1行之间，对这两行都有贡献。对第0行第3列种子点的贡献因子为$dr$，对第1行第3列的贡献因子为$1-dr$，同理，对邻近两列的贡献因子为$dc$和$1-dc$，对邻近两个方向的贡献因子为$do$和$1-do$。则最终累加在每个方向上的梯度大小为：</p>
<script type="math/tex; mode=display">
weight=w∗dr^k(1−dr)^{(1−k)}dc^m(1−dc)^{1−m}do^n(1−do)^{1−n}</script><p>其中k，m，n为0或为1。 如上统计$4∗4∗8=128$个梯度信息即为该关键点的特征向量，按照特征点的对每个关键点的特征向量进行排序，就得到了SIFT特征描述向量。</p>
<p>SIFT在图像的不变特征提取方面拥有无与伦比的优势，但并不完美，仍然存在实时性不高，有时特征点较少，对边缘光滑的目标无法准确提取特征点等缺陷，自SIFT算法问世以来，人们就一直对其进行优化和改进，其中最著名的就是SURF算法。</p>
<h4 id="SURF原理"><a href="#SURF原理" class="headerlink" title="SURF原理"></a>SURF原理</h4><p>使用 SIFT 算法进行关键点检测和描述的执行速度比较慢， 需要速度更快的算法。 2006 年 Bay提出了 SURF 算法，是SIFT算法的增强版，它的计算量小，运算速度快，提取的特征与SIFT几乎相同，将其与SIFT算法对比如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>SIFT</th>
<th>SURF</th>
</tr>
</thead>
<tbody>
<tr>
<td>特征点检测</td>
<td>使用不同尺度的图片与高斯函数进行卷积</td>
<td>使用不同大小的盒滤波器与原始图像做卷积，易于并行</td>
</tr>
<tr>
<td>方向</td>
<td>关键点邻接矩形区域内，利用梯度直方图计算</td>
<td>关键点邻接圆域内，计算x,y方向的haar小波</td>
</tr>
<tr>
<td>描述符生成</td>
<td>关键点领域内划分d*d子区域，每个子区域计算8个方向的直方图</td>
<td>关键点领域内划分d*d个子区域，每个子区域计算采样点的haar小波响应，记录：$\sum dx,\sum dy,\sum</td>
<td>dx</td>
<td>,\sum</td>
<td>dy</td>
<td>$</td>
</tr>
</tbody>
</table>
</div>
<h4 id="OpenCV实现"><a href="#OpenCV实现" class="headerlink" title="OpenCV实现"></a>OpenCV实现</h4><p>在OpenCV中利用SIFT检测关键点的流程如下所示：</p>
<p>1、实例化sift</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sift = cv.xfeatures2d.SIFT_create()</span><br></pre></td></tr></table></figure>
<p>2、利用sift.detectAndCompute()检测关键点并计算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kp,des = sift.detectAndCompute(gray,<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>gray: 进行关键点检测的图像，注意是灰度图像</li>
</ul>
<p>返回值：</p>
<ul>
<li>kp: 关键点信息，包括位置，尺度，方向信息</li>
<li>des: 关键点描述符，每个关键点对应128个梯度信息的特征向量</li>
</ul>
<p>3、将关键点检测结果绘制在图像上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.drawKeypoints(image, keypoints, outputimage, color, flags)</span><br></pre></td></tr></table></figure>
<ul>
<li>image: 原始图像</li>
<li>keypoints：关键点信息，将其绘制在图像上</li>
<li>outputimage：输出图片，可以是原始图像</li>
<li>color：颜色设置，通过修改（b,g,r）的值,更改画笔的颜色，b=蓝色，g=绿色，r=红色。</li>
<li>flags：绘图功能的标识设置<ul>
<li>cv2.DRAW_MATCHES_FLAGS_DEFAULT：创建输出图像矩阵，使用现存的输出图像绘制匹配对和特征点，对每一个关键点只绘制中间点</li>
<li>cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG：不创建输出图像矩阵，而是在输出图像上绘制匹配对</li>
<li>cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS：对每一个特征点绘制带大小和方向的关键点图形</li>
<li>cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS：单点的特征点不被绘制</li>
</ul>
</li>
</ul>
<p>SURF算法的应用与上述流程是一致，这里就不在赘述。</p>
<p>利用SIFT算法在中央电视台的图片上检测关键点，并将其绘制出来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/tv.jpg&#x27;</span>)</span><br><span class="line">gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 2 sift关键点检测</span></span><br><span class="line"><span class="comment"># 2.1 实例化sift对象</span></span><br><span class="line">sift = cv.xfeatures2d.SIFT_create()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 关键点检测：kp关键点信息包括方向，尺度，位置信息，des是关键点的描述符</span></span><br><span class="line">kp,des=sift.detectAndCompute(gray,<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 2.3 在图像上绘制关键点的检测结果</span></span><br><span class="line">cv.drawKeypoints(img,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;sift检测&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191009181525538.png" alt="image-20191009181525538" style="zoom: 50%;" /></p>
<h3 id="Fast算法"><a href="#Fast算法" class="headerlink" title="Fast算法"></a>Fast算法</h3><p>我们前面已经介绍过几个特征检测器，它们的效果都很好，特别是SIFT和SURF算法，但是从<strong>实时</strong>处理的角度来看，效率还是太低了。为了解决这个问题，Edward Rosten和Tom Drummond在2006年提出了FAST算法，并在2010年对其进行了修正。</p>
<p><strong>FAST</strong> (全称Features from accelerated segment test)是一种用于角点检测的算法，该算法的原理是取图像中检测点，以该点为圆心的周围邻域内像素点判断检测点是否为角点，通俗的讲就是<strong>若一个像素周围有一定数量的像素与该点像素值不同，则认为其为角点</strong>。</p>
<h4 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h4><ol>
<li><p>在图像中选取一个像素点 p，来判断它是不是关键点。$I_p$等于像素点 p的灰度值。</p>
</li>
<li><p>以r为半径画圆，覆盖p点周围的M个像素，通常情狂下，设置 r=3，则 M=16，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image17.jpg" alt="image17"></p>
</li>
<li><p>设置一个阈值t，如果在这 16 个像素点中存在 n 个连续像素点的灰度值都高于$I_p + t$，或者低于$I_p - t$，那么像素点 p 就被认为是一个角点。如上图中的虚线所示，n 一般取值为 12。</p>
</li>
<li><p>由于在检测特征点时是需要对图像中所有的像素点进行检测，然而图像中的绝大多数点都不是特征点，如果对每个像素点都进行上述的检测过程，那显然会浪费许多时间，因此采用一种进行<strong>非特征点判别</strong>的方法：首先对候选点的周围每个 90 度的点：1，9，5，13 进行测试（先测试 1 和 19, 如果它们符合阈值要求再测试 5 和 13）。如果 p 是角点，那么这四个点中至少有 3 个要符合阈值要求，否则直接剔除。对保留下来的点再继续进行测试（是否有 12 的点符合阈值要求）。 </p>
</li>
</ol>
<p>虽然这个检测器的效率很高，但它有以下几条缺点：</p>
<ul>
<li>获得的候选点比较多</li>
<li>特征点的选取不是最优的，因为它的效果取决与要解决的问题和角点的分布情况。</li>
<li>进行非特征点判别时大量的点被丢弃</li>
<li>检测到的很多特征点都是相邻的</li>
</ul>
<p>前 3 个问题可以通过机器学习的方法解决，最后一个问题可以使用非最大值抑制的方法解决。</p>
<h4 id="机器学习的角点检测器"><a href="#机器学习的角点检测器" class="headerlink" title="机器学习的角点检测器"></a>机器学习的角点检测器</h4><ol>
<li><p>选择一组训练图片（最好是跟最后应用相关的图片）</p>
</li>
<li><p>使用 FAST 算法找出每幅图像的特征点，对图像中的每一个特征点，将其周围的 16 个像素存储构成一个向量P。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010114459269.png" alt="image-20191010114459269"></p>
</li>
<li><p>每一个特征点的 16 像素点都属于下列三类中的一种</p>
<script type="math/tex; mode=display">
S_{p\rightarrow x}=\left\{ \begin{aligned} 
d, \quad I_{p\rightarrow{x}} \leq I_p-t \quad (darker) \\ 
s, \quad I_p-t \leq I_p+t \quad (similar) \\
b, \quad I_p+t \leq I_{p\rightarrow{x}} \quad (brighter)
\end{aligned}\right.</script></li>
<li><p>根据这些像素点的分类，特征向量 P 也被分为 3 个子集：Pd ，Ps ，Pb，</p>
</li>
<li><p>定义一个新的布尔变量$K_p$，如果 p 是角点就设置为 Ture，如果不是就设置为 False。</p>
</li>
<li><p>利用特征值向量p，目标值是$K_p$，训练ID3 树（决策树分类器）。</p>
</li>
<li><p>将构建好的决策树运用于其他图像的快速的检测。</p>
</li>
</ol>
<h4 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h4><p><strong>在筛选出来的候选角点中有很多是紧挨在一起的，需要通过非极大值抑制来消除这种影响。</strong></p>
<p>为所有的候选角点都确定一个打分函数$V$ ， $V$的值可这样计算：先分别计算$I_p$与圆上16个点的像素值差值，取绝对值，再将这16个绝对值相加，就得到了$V$的值</p>
<script type="math/tex; mode=display">
V = \sum_{i}^{16}|I_p-I_i|</script><p>最后比较毗邻候选角点的 V 值，把V值较小的候选角点pass掉。</p>
<p>FAST算法的思想与我们对角点的直观认识非常接近，化繁为简。FAST算法比其它角点的检测算法快，但是在噪声较高时不够稳定，这需要设置合适的阈值。</p>
<h4 id="OpenCV实现-1"><a href="#OpenCV实现-1" class="headerlink" title="OpenCV实现"></a>OpenCV实现</h4><p>OpenCV中的FAST检测算法是用传统方法实现的，</p>
<p>1、实例化fast</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fast = =cv.FastFeatureDetector_create( threshold, nonmaxSuppression)</span><br></pre></td></tr></table></figure>
<ul>
<li>threshold：阈值t，有默认值10</li>
<li>nonmaxSuppression：是否进行非极大值抑制，默认值True</li>
<li>返回值Fast：创建的FastFeatureDetector对象</li>
</ul>
<p>2、利用fast.detect检测关键点，没有对应的关键点描述</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kp = fast.detect(grayImg, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>gray: 进行关键点检测的图像，注意是灰度图像</li>
<li>kp: 关键点信息，包括位置，尺度，方向信息</li>
</ul>
<p>3、将关键点检测结果绘制在图像上，与在sift中是一样的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.drawKeypoints(image, keypoints, outputimage, color, flags)</span><br></pre></td></tr></table></figure>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/tv.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 2 Fast角点检测</span></span><br><span class="line"><span class="comment"># 2.1 创建一个Fast对象，传入阈值，注意：可以处理彩色空间图像</span></span><br><span class="line">fast = cv.FastFeatureDetector_create(threshold=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 检测图像上的关键点</span></span><br><span class="line">kp = fast.detect(img,<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 2.3 在图像上绘制关键点</span></span><br><span class="line">img2 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.4 输出默认参数</span></span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Threshold: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getThreshold()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;nonmaxSuppression:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getNonmaxSuppression()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;neighborhood: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getType()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Total Keypoints with nonmaxSuppression: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp)) )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.5 关闭非极大值抑制</span></span><br><span class="line">fast.setNonmaxSuppression(<span class="number">0</span>)</span><br><span class="line">kp = fast.detect(img,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Total Keypoints without nonmaxSuppression: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp)) )</span><br><span class="line"><span class="comment"># 2.6 绘制为进行非极大值抑制的结果</span></span><br><span class="line">img3 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 绘制图像</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img2[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;加入非极大值抑制&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(img3[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;未加入非极大值抑制&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010120822413.png" alt="image-20191010120822413" style="zoom: 50%;" /></p>
<h3 id="ORB算法"><a href="#ORB算法" class="headerlink" title="ORB算法"></a>ORB算法</h3><p>SIFT和SURF算法是受专利保护的，在使用他们时我们是要付费的，但是ORB（Oriented Fast and Rotated Brief）不需要，它可以用来对图像中的关键点快速创建特征向量，并用这些特征向量来识别图像中的对象。</p>
<h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><p>ORB算法结合了Fast和Brief算法，提出了构造金字塔，为Fast特征点添加了方向，从而使得关键点具有了尺度不变性和旋转不变性。具体流程描述如下：</p>
<ul>
<li>构造尺度金字塔，金字塔共有n层，与SIFT不同的是，每一层仅有一幅图像。第s层的尺度为：</li>
</ul>
<script type="math/tex; mode=display">
\sigma_s=\sigma_0^s</script><p>$\sigma_0$是初始尺度，默认为1.2，原图在第0层。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010145652681.png" alt="image-20191010145652681"></p>
<p>第s层图像的大小：</p>
<script type="math/tex; mode=display">
SIZE = (H*\frac{1}{\sigma_s})\times(W*\frac{1}{\sigma_s})</script><ul>
<li><p>在不同的尺度上利用Fast算法检测特征点，采用Harris角点响应函数，根据角点的响应值排序，选取前N个特征点，作为本尺度的特征点。</p>
</li>
<li><p>计算特征点的主方向，计算以特征点为圆心半径为r的圆形邻域内的灰度质心位置，将从特征点位置到质心位置的方向做特征点的主方向。</p>
</li>
</ul>
<p>计算方法如下:</p>
<script type="math/tex; mode=display">
m_{pq}=\sum_{x,y}x^py^qI(x,y)</script><p>质心位置：</p>
<script type="math/tex; mode=display">
C=(\frac{m_{10}}{m_{00}},\frac{m_{01}}{m_{10}})</script><p>主方向：</p>
<script type="math/tex; mode=display">
\theta = arctan(m_{01},m_{10})</script><ul>
<li>为了解决旋转不变性，将特征点的邻域旋转到主方向上利用Brief算法构建特征描述符，至此就得到了ORB的特征描述向量。</li>
</ul>
<h4 id="BRIEF算法"><a href="#BRIEF算法" class="headerlink" title="BRIEF算法"></a>BRIEF算法</h4><p>BRIEF是一种特征描述子提取算法，并非特征点的提取算法，一种生成<strong>二值</strong>化描述子的算法，不提取代价低，匹配只需要使用简单的汉明距离(Hamming Distance)利用比特之间的异或操作就可以完成。因此，时间代价低，空间代价低，效果还挺好是最大的优点。</p>
<p><strong>算法的步骤介绍如下</strong>：</p>
<ol>
<li><p><strong>图像滤波</strong>：原始图像中存在噪声时，会对结果产生影响，所以需要对图像进行滤波，去除部分噪声。</p>
</li>
<li><p><strong>选取点对</strong>：以特征点为中心，取S*S的邻域窗口，在窗口内随机选取N组点对，一般N=128,256,512，默认是256，关于如何选取随机点对，提供了五种形式，结果如下图所示：</p>
<ul>
<li><p>x,y方向平均分布采样</p>
</li>
<li><p>x,y均服从Gauss(0,S^2/25)各向同性采样</p>
</li>
<li><p>x服从Gauss(0,S^2/25)，y服从Gauss(0,S^2/100)采样</p>
</li>
<li><p>x,y从网格中随机获取</p>
</li>
<li><p>x一直在(0,0)，y从网格中随机选取</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010153907973.png" alt="image-20191010153907973" style="zoom:67%;" /></p>
</li>
</ul>
<p>图中一条线段的两个端点就是一组点对，其中第二种方法的结果比较好。</p>
</li>
<li><p><strong>构建描述符</strong>：假设x,y是某个点对的两个端点，p(x),p(y)是两点对应的像素值，则有：</p>
<script type="math/tex; mode=display">
t(x,y)=\begin{cases}1    &if p(x)>p(y)\\
0&    else\end{cases}</script><p>对每一个点对都进行上述的二进制赋值，形成BRIEF的关键点的描述特征向量，该向量一般为 128-512 位的字符串，其中仅包含 1 和 0，如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010161944491.png" alt="image-20191010161944491"></p>
</li>
</ol>
<h4 id="OpenCV实现-2"><a href="#OpenCV实现-2" class="headerlink" title="OpenCV实现"></a>OpenCV实现</h4><p>在OPenCV中实现ORB算法，使用的是：</p>
<p>1、实例化ORB</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">orb = cv.xfeatures2d.orb_create(nfeatures)</span><br></pre></td></tr></table></figure>
<ul>
<li>nfeatures: 特征点的最大数量</li>
</ul>
<p>2、利用orb.detectAndCompute()检测关键点并计算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kp,des = orb.detectAndCompute(gray,<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>gray: 进行关键点检测的图像，注意是灰度图像</p>
</li>
<li><p>kp: 关键点信息，包括位置，尺度，方向信息</p>
</li>
<li>des: 关键点描述符，每个关键点BRIEF特征向量，二进制字符串，</li>
</ul>
<p>3、将关键点检测结果绘制在图像上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.drawKeypoints(image, keypoints, outputimage, color, flags)</span><br></pre></td></tr></table></figure>
<p><strong>示例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像读取</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/tv.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 ORB角点检测</span></span><br><span class="line"><span class="comment"># 2.1 实例化ORB对象</span></span><br><span class="line">orb = cv.ORB_create(nfeatures=<span class="number">500</span>)</span><br><span class="line"><span class="comment"># 2.2 检测关键点,并计算特征描述符</span></span><br><span class="line">kp,des = orb.detectAndCompute(img,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(des.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 将关键点绘制在图像上</span></span><br><span class="line">img2 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), flags=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 绘制图像</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img2[:,:,::-<span class="number">1</span>])</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191010162532196.png" alt="image-20191010162532196" style="zoom:67%;" /></p>
<p><strong>总结</strong></p>
<ol>
<li><p>Fast算法</p>
<p>原理：若一个像素周围有一定数量的像素与该点像素值不同，则认为其为角点</p>
<p>API: cv.FastFeatureDetector_create()</p>
</li>
<li><p>ORB算法</p>
<p>原理：是FAST算法和BRIEF算法的结合</p>
<p>API：cv.ORB_create()</p>
</li>
</ol>
<h2 id="视频操作"><a href="#视频操作" class="headerlink" title="视频操作"></a>视频操作</h2><ul>
<li>视频文件的读取和存储</li>
<li>视频追踪中的meanshift和camshift算法</li>
</ul>
<h3 id="视频读写"><a href="#视频读写" class="headerlink" title="视频读写"></a>视频读写</h3><h4 id="读取视频"><a href="#读取视频" class="headerlink" title="读取视频"></a>读取视频</h4><p>在OpenCV中我们要获取一个视频，需要创建一个VideoCapture对象，指定你要读取的视频文件：</p>
<ol>
<li><p>创建读取视频的对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cap = cv.VideoCapture(filepath)</span><br></pre></td></tr></table></figure>
<ul>
<li>filepath: 视频文件路径</li>
</ul>
</li>
<li><p>视频的属性信息</p>
<p>2.1. 获取视频的某些属性，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">retval = cap.get(propId)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>propId: 从0到18的数字，每个数字表示视频的属性。常用属性有：</p>
<p>| 索引 | flags                      | 意义                               |<br>| —— | ————————————— | ————————————————— |<br>| 0    | cv2.CAP_PROP_POS_MSEC      | 视频文件的当前位置（ms）           |<br>| 1    | cv2.CAP_PROP_POS_FRAMES    | 从0开始索引帧，帧位置              |<br>| 2    | cv2.CAP_PROP_POS_AVI_RATIO | 视频文件的相对位置（0开始，1结束） |<br>| 3    | cv2.CAP_PROP_FRAME_WIDTH   | 视频流的帧宽度                     |<br>| 4    | cv2.CAP_PROP_FRAME_HEIGHT  | 视频流的帧高度                     |<br>| 5    | cv2.CAP_PROP_FPS           | 帧率                               |<br>| 6    | cv2.CAP_PROP_FOURCC        | 编解码器四字符代码                 |<br>| 7    | cv2.CAP_PROP_FRAME_COUNT   | 视频文件的帧                       |</p>
</li>
</ul>
<p>2.2 修改视频的属性信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cap.<span class="built_in">set</span>(propId，value)</span><br></pre></td></tr></table></figure>
<ul>
<li>proid: 属性的索引，与上面的表格相对应</li>
<li>value: 修改后的属性值</li>
</ul>
</li>
<li><p>判断图像是否读取成功</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">isornot = cap.isOpened()</span><br></pre></td></tr></table></figure>
<ul>
<li>若读取成功则返回true，否则返回False</li>
</ul>
</li>
<li><p>获取视频的一帧图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ret, frame = cap.read()</span><br></pre></td></tr></table></figure>
<ul>
<li>ret: 若获取成功返回True，获取失败，返回False</li>
<li>Frame: 获取到的某一帧的图像</li>
</ul>
</li>
<li><p>调用cv.imshow()显示图像，在显示图像时使用cv.waitkey()设置适当的持续时间，如果太低视频会播放的非常快，如果太高就会播放的非常慢，通常情况下我们设置25ms就可以了。</p>
</li>
<li><p>最后，调用cap.realease()将视频释放掉</p>
</li>
</ol>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="comment"># 1.获取视频对象</span></span><br><span class="line">cap = cv.VideoCapture(<span class="string">&#x27;DOG.wmv&#x27;</span>)</span><br><span class="line"><span class="comment"># 2.判断是否读取成功</span></span><br><span class="line"><span class="keyword">while</span>(cap.isOpened()):</span><br><span class="line">    <span class="comment"># 3.获取每一帧图像</span></span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="comment"># 4. 获取成功显示图像</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        cv.imshow(<span class="string">&#x27;frame&#x27;</span>,frame)</span><br><span class="line">    <span class="comment"># 5.每一帧间隔为25ms</span></span><br><span class="line">    <span class="keyword">if</span> cv.waitKey(<span class="number">25</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="comment"># 6.释放视频对象</span></span><br><span class="line">cap.release()</span><br><span class="line">cv.destoryAllwindows()</span><br></pre></td></tr></table></figure>
<h4 id="保存视频"><a href="#保存视频" class="headerlink" title="保存视频"></a>保存视频</h4><p>在OpenCV中我们保存视频使用的是VedioWriter对象，在其中指定输出文件的名称，如下所示：</p>
<p>创建视频写入的对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out = cv2.VideoWriter(filename,fourcc, fps, frameSize)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>filename：视频保存的位置</p>
</li>
<li><p>fourcc：指定视频编解码器的4字节代码</p>
</li>
<li><p>fps：帧率</p>
</li>
<li><p>frameSize：帧大小</p>
</li>
</ul>
<p>设置视频的编解码器fourcc，如下所示，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">retval = cv2.VideoWriter_fourcc( c1, c2, c3, c4 )</span><br></pre></td></tr></table></figure>
<ul>
<li><p>c1,c2,c3,c4: 是视频编解码器的4字节代码，在<a target="_blank" rel="noopener" href="http://www.fourcc.org/codecs.php">fourcc.org</a>中找到可用代码列表，与平台紧密相关，常用的有：</p>
<p>在Windows中：DIVX（.avi）</p>
<p>在OS中：MJPG（.mp4），DIVX（.avi），X264（.mkv）。</p>
</li>
<li><p>利用cap.read()获取视频中的每一帧图像，并使用out.write()将某一帧图像写入视频中。</p>
</li>
<li><p>使用cap.release()和out.release()释放资源。</p>
</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 读取视频</span></span><br><span class="line">cap = cv.VideoCapture(<span class="string">&quot;DOG.wmv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 获取图像的属性（宽和高，）,并将其转换为整数</span></span><br><span class="line">frame_width = <span class="built_in">int</span>(cap.get(<span class="number">3</span>))</span><br><span class="line">frame_height = <span class="built_in">int</span>(cap.get(<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 创建保存视频的对象，设置编码格式，帧率，图像的宽高等</span></span><br><span class="line">out = cv.VideoWriter(<span class="string">&#x27;outpy.avi&#x27;</span>,cv.VideoWriter_fourcc(<span class="string">&#x27;M&#x27;</span>,<span class="string">&#x27;J&#x27;</span>,<span class="string">&#x27;P&#x27;</span>,<span class="string">&#x27;G&#x27;</span>), <span class="number">10</span>, (frame_width,frame_height))</span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    <span class="comment"># 4.获取视频中的每一帧图像</span></span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>: </span><br><span class="line">        <span class="comment"># 5.将每一帧图像写入到输出文件中</span></span><br><span class="line">        out.write(frame)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.释放资源</span></span><br><span class="line">cap.release()</span><br><span class="line">out.release()</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<h3 id="视频追踪"><a href="#视频追踪" class="headerlink" title="视频追踪"></a>视频追踪</h3><h4 id="meanshift算法"><a href="#meanshift算法" class="headerlink" title="meanshift算法"></a>meanshift算法</h4><p>meanshift算法的原理很简单。假设你有一堆点集，还有一个小的窗口，这个窗口可能是圆形的，现在你可能要移动这个窗口到点集密度最大的区域当中。</p>
<p>如下图：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image1-0784863-16777246863615.jpg" alt="image1" style="zoom: 80%;" /></p>
<p>最开始的窗口是蓝色圆环的区域，命名为C1。蓝色圆环的圆心用一个蓝色的矩形标注，命名为C1_o。</p>
<p>而窗口中所有点的点集构成的质心在蓝色圆形点C1_r处，显然圆环的形心和质心并不重合。所以，移动蓝色的窗口，使得形心与之前得到的质心重合。在新移动后的圆环的区域当中再次寻找圆环当中所包围点集的质心，然后再次移动，通常情况下，形心和质心是不重合的。不断执行上面的移动过程，直到形心和质心大致重合结束。 这样，最后圆形的窗口会落到像素分布最大的地方，也就是图中的绿色圈，命名为C2。</p>
<p>meanshift算法除了应用在视频追踪当中，在聚类，平滑等等各种涉及到数据以及非监督学习的场合当中均有重要应用，是一个应用广泛的算法。</p>
<p>图像是一个矩阵信息，如何在一个视频当中使用meanshift算法来追踪一个运动的物体呢？ 大致流程如下：</p>
<ol>
<li><p>首先在图像上选定一个目标区域</p>
</li>
<li><p>计算选定区域的直方图分布，一般是HSV色彩空间的直方图。</p>
</li>
<li><p>对下一帧图像b同样计算直方图分布。</p>
</li>
<li><p>计算图像b当中与选定区域直方图分布最为相似的区域，使用meanshift算法将选定区域沿着最为相似的部分进行移动，直到找到最相似的区域，便完成了在图像b中的目标追踪。</p>
</li>
<li><p>重复3到4的过程，就完成整个视频目标追踪。</p>
<p>通常情况下我们使用直方图反向投影得到的图像和第一帧目标对象的起始位置，当目标对象的移动会反映到直方图反向投影图中，meanshift 算法就把我们的窗口移动到反向投影图像中灰度密度最大的区域了。如下图所示：</p>
</li>
</ol>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image2-0785334-16777247135957.gif" alt="image2"></p>
<p>直方图反向投影的流程是：</p>
<p>假设我们有一张100x100的输入图像，有一张10x10的模板图像，查找的过程是这样的：</p>
<ol>
<li>从输入图像的左上角(0,0)开始，切割一块(0,0)至(10,10)的临时图像；</li>
<li>生成临时图像的直方图；</li>
<li>用临时图像的直方图和模板图像的直方图对比，对比结果记为c；</li>
<li>直方图对比结果c，就是结果图像(0,0)处的像素值；</li>
<li>切割输入图像从(0,1)至(10,11)的临时图像，对比直方图，并记录到结果图像；</li>
<li>重复1～5步直到输入图像的右下角，就形成了直方图的反向投影。</li>
</ol>
<p>在OpenCV中实现Meanshift的API是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.meanShift(probImage, window, criteria)</span><br></pre></td></tr></table></figure>
<ul>
<li>probImage: ROI区域，即目标的直方图的反向投影</li>
<li>window： 初始搜索窗口，就是定义ROI的rect</li>
<li>criteria: 确定窗口搜索停止的准则，主要有迭代次数达到设置的最大值，窗口中心的漂移值大于某个设定的限值等。</li>
</ul>
<p>实现Meanshift的主要流程是：</p>
<ol>
<li>读取视频文件：cv.videoCapture()</li>
<li>感兴趣区域设置：获取第一帧图像，并设置目标区域，即感兴趣区域</li>
<li>计算直方图：计算感兴趣区域的HSV直方图，并进行归一化</li>
<li>目标追踪：设置窗口搜索停止条件，直方图反向投影，进行目标追踪，并在目标位置绘制矩形框。</li>
</ol>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="comment"># 1.获取图像</span></span><br><span class="line">cap = cv.VideoCapture(<span class="string">&#x27;DOG.wmv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.获取第一帧图像，并指定目标位置</span></span><br><span class="line">ret,frame = cap.read()</span><br><span class="line"><span class="comment"># 2.1 目标位置（行，高，列，宽）</span></span><br><span class="line">r,h,c,w = <span class="number">197</span>,<span class="number">141</span>,<span class="number">0</span>,<span class="number">208</span>  </span><br><span class="line">track_window = (c,r,w,h)</span><br><span class="line"><span class="comment"># 2.2 指定目标的感兴趣区域</span></span><br><span class="line">roi = frame[r:r+h, c:c+w]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 计算直方图</span></span><br><span class="line"><span class="comment"># 3.1 转换色彩空间（HSV）</span></span><br><span class="line">hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)</span><br><span class="line"><span class="comment"># 3.2 去除低亮度的值</span></span><br><span class="line"><span class="comment"># mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))</span></span><br><span class="line"><span class="comment"># 3.3 计算直方图</span></span><br><span class="line">roi_hist = cv.calcHist([hsv_roi],[<span class="number">0</span>],<span class="literal">None</span>,[<span class="number">180</span>],[<span class="number">0</span>,<span class="number">180</span>])</span><br><span class="line"><span class="comment"># 3.4 归一化</span></span><br><span class="line">cv.normalize(roi_hist,roi_hist,<span class="number">0</span>,<span class="number">255</span>,cv.NORM_MINMAX)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 目标追踪</span></span><br><span class="line"><span class="comment"># 4.1 设置窗口搜索终止条件：最大迭代次数，窗口中心漂移最小值</span></span><br><span class="line">term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, <span class="number">10</span>, <span class="number">1</span> )</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    <span class="comment"># 4.2 获取每一帧图像</span></span><br><span class="line">    ret ,frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 4.3 计算直方图的反向投影</span></span><br><span class="line">        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)</span><br><span class="line">        dst = cv.calcBackProject([hsv],[<span class="number">0</span>],roi_hist,[<span class="number">0</span>,<span class="number">180</span>],<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4.4 进行meanshift追踪</span></span><br><span class="line">        ret, track_window = cv.meanShift(dst, track_window, term_crit)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4.5 将追踪的位置绘制在视频上，并进行显示</span></span><br><span class="line">        x,y,w,h = track_window</span><br><span class="line">        img2 = cv.rectangle(frame, (x,y), (x+w,y+h), <span class="number">255</span>,<span class="number">2</span>)</span><br><span class="line">        cv.imshow(<span class="string">&#x27;frame&#x27;</span>,img2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cv.waitKey(<span class="number">60</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">            <span class="keyword">break</span>        </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="comment"># 5. 资源释放        </span></span><br><span class="line">cap.release()</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>下面是三帧图像的跟踪结果：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191011180244485-16777247467209.png" alt="image-20191011180244485" style="zoom: 50%;" /></p>
<p><strong>Meanshift算法：简单，迭代次数少，但无法解决目标的遮挡问题并且不能适应运动目标的的形状和大小变化。</strong></p>
<h4 id="Camshift算法"><a href="#Camshift算法" class="headerlink" title="Camshift算法"></a>Camshift算法</h4><p>大家认真看下上面的结果，有一个问题，就是检测的窗口的大小是固定的，而狗狗由近及远是一个逐渐变小的过程，固定的窗口是不合适的。所以我们需要根据目标的大小和角度来对窗口的大小和角度进行修正。CamShift可以帮我们解决这个问题。</p>
<p>CamShift算法全称是“Continuously Adaptive Mean-Shift”（连续自适应MeanShift算法），是对MeanShift算法的改进算法，可随着跟踪目标的大小变化实时调整搜索窗口的大小，具有较好的跟踪效果。</p>
<p>Camshift算法首先应用meanshift，一旦meanshift收敛，它就会更新窗口的大小，还计算最佳拟合椭圆的方向，从而根据目标的位置和大小更新搜索窗口。如下图所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image4-167772478479211.gif" alt="image4"></p>
<p>Camshift在OpenCV中实现时，只需将上述的meanshift函数改为Camshift函数即可：</p>
<p>将Camshift中的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.4 进行meanshift追踪</span></span><br><span class="line">       ret, track_window = cv.meanShift(dst, track_window, term_crit)</span><br><span class="line"></span><br><span class="line">       <span class="comment"># 4.5 将追踪的位置绘制在视频上，并进行显示</span></span><br><span class="line">       x,y,w,h = track_window</span><br><span class="line">       img2 = cv.rectangle(frame, (x,y), (x+w,y+h), <span class="number">255</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#进行camshift追踪</span></span><br><span class="line">  ret, track_window = cv.CamShift(dst, track_window, term_crit)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 绘制追踪结果</span></span><br><span class="line">      pts = cv.boxPoints(ret)</span><br><span class="line">      pts = np.int0(pts)</span><br><span class="line">      img2 = cv.polylines(frame,[pts],<span class="literal">True</span>, <span class="number">255</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><strong>camshift算法：可适应运动目标的大小形状的改变，具有较好的跟踪效果，但当背景色和目标颜色接近时，容易使目标的区域变大，最终有可能导致目标跟踪丢失。</strong></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>读取视频：</p>
<ul>
<li>读取视频：cap = cv.VideoCapture()</li>
<li>判断读取成功：cap.isOpened()</li>
<li>读取每一帧图像：ret,frame = cap.read()</li>
<li>获取属性：cap.get(proid)</li>
<li>设置属性：cap.set(proid,value)</li>
<li>资源释放：cap.release()</li>
</ul>
<p>保存视频</p>
<ul>
<li>保存视频： out = cv.VideoWrite()</li>
<li>视频写入：out.write()</li>
<li>资源释放：out.release()</li>
</ul>
<p>meanshift</p>
<ul>
<li>原理：一个迭代的步骤，即先算出当前点的偏移均值，移动该点到其偏移均值，然后以此为新的起始点，继续移动，直到满足一定的条件结束。</li>
<li>API：cv.meanshift()</li>
<li>优缺点：简单，迭代次数少，但无法解决目标的遮挡问题并且不能适应运动目标的的形状和大小变化</li>
</ul>
<p>camshift</p>
<ul>
<li>原理：对meanshift算法的改进，首先应用meanshift，一旦meanshift收敛，它就会更新窗口的大小，还计算最佳拟合椭圆的方向，从而根据目标的位置和大小更新搜索窗口。</li>
<li>API：cv.camshift()</li>
<li>优缺点：可适应运动目标的大小形状的改变，具有较好的跟踪效果，但当背景色和目标颜色接近时，容易使目标的区域变大，最终有可能导致目标跟踪丢失</li>
</ul>
<h2 id="案例-人脸案例"><a href="#案例-人脸案例" class="headerlink" title="案例:人脸案例"></a>案例:人脸案例</h2><p>我们使用机器学习的方法完成人脸检测，首先需要大量的正样本图像（面部图像）和负样本图像（不含面部的图像）来训练分类器。我们需要从其中提取特征。下图中的 Haar 特征会被使用，就像我们的卷积核，每一个特征是一 个值，这个值等于黑色矩形中的像素值之后减去白色矩形中的像素值之和。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014152218924-167772525674113.png" alt="image-20191014152218924" style="zoom:50%;" /></p>
<p>Haar特征值反映了图像的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。</p>
<p>Haar特征可用于于图像任意位置，大小也可以任意改变，所以矩形特征值是矩形模版类别、矩形位置和矩形大小这三个因素的函数。故类别、大小和位置的变化，使得很小的检测窗口含有非常多的矩形特征。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014152716626-167772527072915.png" alt="image-20191014152716626" style="zoom: 50%;" /></p>
<p>得到图像的特征后，训练一个决策树构建的adaboost级联决策器来识别是否为人脸。</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014160504382-167772528427717.png" alt="image-20191014160504382" style="zoom: 50%;" /></p>
<p>OpenCV中自带已训练好的检测器，包括面部，眼睛，猫脸等，都保存在XML文件中，我们可以通过以下程序找到他们：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="built_in">print</span>(cv.__file__)</span><br></pre></td></tr></table></figure>
<p>找到的文件如下所示：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014160719733-167772532593419.png" alt="image-20191014160719733" style="zoom:67%;" /></p>
<p>那我们就利用这些文件来识别人脸，眼睛等。检测流程如下：</p>
<ol>
<li><p>读取图片，并转换成灰度图</p>
</li>
<li><p>实例化人脸和眼睛检测的分类器对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化级联分类器</span></span><br><span class="line">classifier =cv.CascadeClassifier( <span class="string">&quot;haarcascade_frontalface_default.xml&quot;</span> ) </span><br><span class="line"><span class="comment"># 加载分类器</span></span><br><span class="line">classifier.load(<span class="string">&#x27;haarcascade_frontalface_default.xml&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>进行人脸和眼睛的检测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rect = classifier.detectMultiScale(gray, scaleFactor, minNeighbors, minSize,maxsize)</span><br></pre></td></tr></table></figure>
<ul>
<li>Gray: 要进行检测的人脸图像</li>
<li>scaleFactor: 前后两次扫描中，搜索窗口的比例系数</li>
<li>minneighbors：目标至少被检测到minNeighbors次才会被认为是目标</li>
<li>minsize和maxsize: 目标的最小尺寸和最大尺寸</li>
</ul>
</li>
<li><p>将检测结果绘制出来就可以了。</p>
</li>
</ol>
<p>主程序如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1.以灰度图的形式读取图片</span></span><br><span class="line">img = cv.imread(<span class="string">&quot;16.jpg&quot;</span>)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.实例化OpenCV人脸和眼睛识别的分类器 </span></span><br><span class="line">face_cas = cv.CascadeClassifier( <span class="string">&quot;haarcascade_frontalface_default.xml&quot;</span> ) </span><br><span class="line">face_cas.load(<span class="string">&#x27;haarcascade_frontalface_default.xml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">eyes_cas = cv.CascadeClassifier(<span class="string">&quot;haarcascade_eye.xml&quot;</span>)</span><br><span class="line">eyes_cas.load(<span class="string">&quot;haarcascade_eye.xml&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.调用识别人脸 </span></span><br><span class="line">faceRects = face_cas.detectMultiScale( gray, scaleFactor=<span class="number">1.2</span>, minNeighbors=<span class="number">3</span>, minSize=(<span class="number">32</span>, <span class="number">32</span>)) </span><br><span class="line"><span class="keyword">for</span> faceRect <span class="keyword">in</span> faceRects: </span><br><span class="line">    x, y, w, h = faceRect </span><br><span class="line">    <span class="comment"># 框出人脸 </span></span><br><span class="line">    cv.rectangle(img, (x, y), (x + h, y + w),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">3</span>) </span><br><span class="line">    <span class="comment"># 4.在识别出的人脸中进行眼睛的检测</span></span><br><span class="line">    roi_color = img[y:y+h, x:x+w]</span><br><span class="line">    roi_gray = gray[y:y+h, x:x+w]</span><br><span class="line">    eyes = eyes_cas.detectMultiScale(roi_gray) </span><br><span class="line">    <span class="keyword">for</span> (ex,ey,ew,eh) <span class="keyword">in</span> eyes:</span><br><span class="line">        cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 5. 检测结果的绘制</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;检测结果&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/Imgproc-img/image-20191014164455020-167772535167121.png" alt="image-20191014164455020" style="zoom:50%;" /></p>
<p>我们也可在视频中对人脸进行检测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1.读取视频</span></span><br><span class="line">cap = cv.VideoCapture(<span class="string">&quot;movie.mp4&quot;</span>)</span><br><span class="line"><span class="comment"># 2.在每一帧数据中进行人脸识别</span></span><br><span class="line"><span class="keyword">while</span>(cap.isOpened()):</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> ret==<span class="literal">True</span>:</span><br><span class="line">        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)</span><br><span class="line">        <span class="comment"># 3.实例化OpenCV人脸识别的分类器 </span></span><br><span class="line">        face_cas = cv.CascadeClassifier( <span class="string">&quot;haarcascade_frontalface_default.xml&quot;</span> ) </span><br><span class="line">        face_cas.load(<span class="string">&#x27;haarcascade_frontalface_default.xml&#x27;</span>)</span><br><span class="line">        <span class="comment"># 4.调用识别人脸 </span></span><br><span class="line">        faceRects = face_cas.detectMultiScale(gray, scaleFactor=<span class="number">1.2</span>, minNeighbors=<span class="number">3</span>, minSize=(<span class="number">32</span>, <span class="number">32</span>)) </span><br><span class="line">        <span class="keyword">for</span> faceRect <span class="keyword">in</span> faceRects: </span><br><span class="line">            x, y, w, h = faceRect </span><br><span class="line">            <span class="comment"># 框出人脸 </span></span><br><span class="line">            cv.rectangle(frame, (x, y), (x + h, y + w),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">3</span>) </span><br><span class="line">        cv.imshow(<span class="string">&quot;frame&quot;</span>,frame)</span><br><span class="line">        <span class="keyword">if</span> cv.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"><span class="comment"># 5. 释放资源</span></span><br><span class="line">cap.release()  </span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      
      
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">OpenCV简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AE%80%E4%BB%8B"><span class="nav-number">1.1.</span> <span class="nav-text">图像处理简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">1.1.1.</span> <span class="nav-text">图像是什么</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E6%8B%9F%E5%9B%BE%E5%83%8F%E5%92%8C%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F"><span class="nav-number">1.1.2.</span> <span class="nav-text">模拟图像和数字图像</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E7%9A%84%E8%A1%A8%E7%A4%BA"><span class="nav-number">1.1.3.</span> <span class="nav-text">数字图像的表示</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BD%8D%E6%95%B0"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">位数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84%E5%88%86%E7%B1%BB"><span class="nav-number">1.1.3.2.</span> <span class="nav-text">图像的分类</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85OpenCV"><span class="nav-number">1.2.</span> <span class="nav-text">安装OpenCV</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#OpenCV%E7%AE%80%E4%BB%8B-1"><span class="nav-number">1.2.1.</span> <span class="nav-text">OpenCV简介</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#OpenCV-Python"><span class="nav-number">1.2.2.</span> <span class="nav-text">OpenCV-Python</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#OpenCV%E9%83%A8%E7%BD%B2%E6%96%B9%E6%B3%95"><span class="nav-number">1.2.3.</span> <span class="nav-text">OpenCV部署方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenCV%E7%9A%84%E6%A8%A1%E5%9D%97"><span class="nav-number">1.3.</span> <span class="nav-text">OpenCV的模块</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="nav-number">2.</span> <span class="nav-text">OpenCV基本操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C"><span class="nav-number">2.1.</span> <span class="nav-text">图像的基础操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84IO%E6%93%8D%E4%BD%9C"><span class="nav-number">2.1.1.</span> <span class="nav-text">图像的IO操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%98%E5%88%B6%E5%87%A0%E4%BD%95%E5%9B%BE%E5%BD%A2"><span class="nav-number">2.1.2.</span> <span class="nav-text">绘制几何图形</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96-%E4%BF%AE%E6%94%B9%E5%83%8F%E7%B4%A0%E7%82%B9"><span class="nav-number">2.1.3.</span> <span class="nav-text">获取&#x2F;修改像素点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E5%9B%BE%E5%83%8F%E5%B1%9E%E6%80%A7"><span class="nav-number">2.1.4.</span> <span class="nav-text">获取图像属性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E9%80%9A%E9%81%93%E7%9A%84%E6%8B%86%E5%88%86-%E5%90%88%E5%B9%B6"><span class="nav-number">2.1.5.</span> <span class="nav-text">图像通道的拆分&#x2F;合并</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%97%B4%E7%9A%84%E6%94%B9%E5%8F%98"><span class="nav-number">2.1.6.</span> <span class="nav-text">色彩空间的改变</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E6%95%B0%E6%93%8D%E4%BD%9C"><span class="nav-number">2.2.</span> <span class="nav-text">算数操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84%E5%8A%A0%E6%B3%95"><span class="nav-number">2.2.1.</span> <span class="nav-text">图像的加法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84%E6%B7%B7%E5%90%88"><span class="nav-number">2.2.2.</span> <span class="nav-text">图像的混合</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86"><span class="nav-number">3.</span> <span class="nav-text">OpenCV图像处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%87%A0%E4%BD%95%E5%8F%98%E6%8D%A2"><span class="nav-number">3.1.</span> <span class="nav-text">几何变换</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%BC%A9%E6%94%BE"><span class="nav-number">3.1.1.</span> <span class="nav-text">图像缩放</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%B9%B3%E7%A7%BB"><span class="nav-number">3.1.2.</span> <span class="nav-text">图像平移</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E6%97%8B%E8%BD%AC"><span class="nav-number">3.1.3.</span> <span class="nav-text">图像旋转</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2"><span class="nav-number">3.1.4.</span> <span class="nav-text">仿射变换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%8F%E5%B0%84%E5%8F%98%E6%8D%A2"><span class="nav-number">3.1.5.</span> <span class="nav-text">透射变换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94"><span class="nav-number">3.1.6.</span> <span class="nav-text">图像金字塔</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BD%A2%E6%80%81%E5%AD%A6%E6%93%8D%E4%BD%9C"><span class="nav-number">3.2.</span> <span class="nav-text">形态学操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E9%80%9A%E6%80%A7"><span class="nav-number">3.2.1.</span> <span class="nav-text">连通性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%85%90%E8%9A%80%E5%92%8C%E8%86%A8%E8%83%80"><span class="nav-number">3.2.2.</span> <span class="nav-text">腐蚀和膨胀</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%80%E9%97%AD%E8%BF%90%E7%AE%97"><span class="nav-number">3.2.3.</span> <span class="nav-text">开闭运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A4%BC%E5%B8%BD%E5%92%8C%E9%BB%91%E5%B8%BD"><span class="nav-number">3.2.4.</span> <span class="nav-text">礼帽和黑帽</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%B9%B3%E6%BB%91"><span class="nav-number">3.3.</span> <span class="nav-text">图像平滑</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%99%AA%E5%A3%B0"><span class="nav-number">3.3.1.</span> <span class="nav-text">图像噪声</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A4%92%E7%9B%90%E5%99%AA%E5%A3%B0"><span class="nav-number">3.3.1.1.</span> <span class="nav-text">椒盐噪声</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0"><span class="nav-number">3.3.1.2.</span> <span class="nav-text">高斯噪声</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9D%87%E5%80%BC%E6%BB%A4%E6%B3%A2"><span class="nav-number">3.3.2.</span> <span class="nav-text">均值滤波</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E6%BB%A4%E6%B3%A2"><span class="nav-number">3.3.3.</span> <span class="nav-text">高斯滤波</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%AD%E5%80%BC%E6%BB%A4%E6%B3%A2"><span class="nav-number">3.3.4.</span> <span class="nav-text">中值滤波</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="nav-number">3.4.</span> <span class="nav-text">直方图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%81%B0%E5%BA%A6%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="nav-number">3.4.1.</span> <span class="nav-text">灰度直方图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97-%E7%BB%98%E5%88%B6%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="nav-number">3.4.2.</span> <span class="nav-text">计算&#x2F;绘制直方图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%A9%E8%86%9C%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-number">3.4.3.</span> <span class="nav-text">掩膜的应用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96"><span class="nav-number">3.4.4.</span> <span class="nav-text">直方图均衡化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E9%80%82%E5%BA%94%E7%9A%84%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96"><span class="nav-number">3.4.5.</span> <span class="nav-text">自适应的直方图均衡化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B"><span class="nav-number">3.5.</span> <span class="nav-text">边缘检测</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E5%8E%9F%E7%90%86"><span class="nav-number">3.5.1.</span> <span class="nav-text">边缘检测原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sobel%E7%AE%97%E5%AD%90"><span class="nav-number">3.5.2.</span> <span class="nav-text">Sobel算子</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Laplacian%E7%AE%97%E5%AD%90"><span class="nav-number">3.5.3.</span> <span class="nav-text">Laplacian算子</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Canny%E7%AE%97%E5%AD%90"><span class="nav-number">3.5.4.</span> <span class="nav-text">Canny算子</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%97%E5%AD%90%E6%AF%94%E8%BE%83"><span class="nav-number">3.5.5.</span> <span class="nav-text">算子比较</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E7%89%88%E5%8C%B9%E9%85%8D"><span class="nav-number">3.6.</span> <span class="nav-text">模版匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2"><span class="nav-number">3.7.</span> <span class="nav-text">霍夫变换</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D"><span class="nav-number">3.7.1.</span> <span class="nav-text">原理介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9C%8D%E5%A4%AB%E7%BA%BF%E6%A3%80%E6%B5%8B"><span class="nav-number">3.7.2.</span> <span class="nav-text">霍夫线检测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9C%8D%E5%A4%AB%E5%9C%86%E6%A3%80%E6%B5%8B"><span class="nav-number">3.7.3.</span> <span class="nav-text">霍夫圆检测</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E6%8F%8F%E8%BF%B0"><span class="nav-number">4.</span> <span class="nav-text">图像特征提取与描述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%92%E7%82%B9%E7%89%B9%E5%BE%81"><span class="nav-number">4.1.</span> <span class="nav-text">角点特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Harris%E7%AE%97%E6%B3%95"><span class="nav-number">4.2.</span> <span class="nav-text">Harris算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Shi-Tomasi%E7%AE%97%E6%B3%95"><span class="nav-number">4.3.</span> <span class="nav-text">Shi-Tomasi算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SIFT-SURF%E7%AE%97%E6%B3%95"><span class="nav-number">4.4.</span> <span class="nav-text">SIFT&#x2F;SURF算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%BA%E5%BA%A6%E7%A9%BA%E9%97%B4%E6%9E%81%E5%80%BC%E6%A3%80%E6%B5%8B"><span class="nav-number">4.4.1.</span> <span class="nav-text">尺度空间极值检测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9%E5%AE%9A%E4%BD%8D"><span class="nav-number">4.4.2.</span> <span class="nav-text">关键点定位</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9%E6%96%B9%E5%90%91%E7%A1%AE%E5%AE%9A"><span class="nav-number">4.4.3.</span> <span class="nav-text">关键点方向确定</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9%E6%8F%8F%E8%BF%B0"><span class="nav-number">4.4.4.</span> <span class="nav-text">关键点描述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SURF%E5%8E%9F%E7%90%86"><span class="nav-number">4.4.5.</span> <span class="nav-text">SURF原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#OpenCV%E5%AE%9E%E7%8E%B0"><span class="nav-number">4.4.6.</span> <span class="nav-text">OpenCV实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fast%E7%AE%97%E6%B3%95"><span class="nav-number">4.5.</span> <span class="nav-text">Fast算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="nav-number">4.5.1.</span> <span class="nav-text">基本流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E5%99%A8"><span class="nav-number">4.5.2.</span> <span class="nav-text">机器学习的角点检测器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6"><span class="nav-number">4.5.3.</span> <span class="nav-text">非极大值抑制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#OpenCV%E5%AE%9E%E7%8E%B0-1"><span class="nav-number">4.5.4.</span> <span class="nav-text">OpenCV实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ORB%E7%AE%97%E6%B3%95"><span class="nav-number">4.6.</span> <span class="nav-text">ORB算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">4.6.1.</span> <span class="nav-text">算法流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#BRIEF%E7%AE%97%E6%B3%95"><span class="nav-number">4.6.2.</span> <span class="nav-text">BRIEF算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#OpenCV%E5%AE%9E%E7%8E%B0-2"><span class="nav-number">4.6.3.</span> <span class="nav-text">OpenCV实现</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E6%93%8D%E4%BD%9C"><span class="nav-number">5.</span> <span class="nav-text">视频操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E8%AF%BB%E5%86%99"><span class="nav-number">5.1.</span> <span class="nav-text">视频读写</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E8%A7%86%E9%A2%91"><span class="nav-number">5.1.1.</span> <span class="nav-text">读取视频</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%9D%E5%AD%98%E8%A7%86%E9%A2%91"><span class="nav-number">5.1.2.</span> <span class="nav-text">保存视频</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E8%BF%BD%E8%B8%AA"><span class="nav-number">5.2.</span> <span class="nav-text">视频追踪</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#meanshift%E7%AE%97%E6%B3%95"><span class="nav-number">5.2.1.</span> <span class="nav-text">meanshift算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Camshift%E7%AE%97%E6%B3%95"><span class="nav-number">5.2.2.</span> <span class="nav-text">Camshift算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">5.3.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B-%E4%BA%BA%E8%84%B8%E6%A1%88%E4%BE%8B"><span class="nav-number">6.</span> <span class="nav-text">案例:人脸案例</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="yanglinqi"
      src="/images/headpic.jpg">
  <p class="site-author-name" itemprop="name">yanglinqi</p>
  <div class="site-description" itemprop="description">用于做笔记，对学过的知识总结</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">98</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yanglinqi107" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yanglinqi107" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yanglinqi</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.1.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


  <script async src="/js/cursor/fireworks.js"></script>


</body>
</html>
