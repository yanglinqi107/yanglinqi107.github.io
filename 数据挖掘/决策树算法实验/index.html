<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
<meta name="referrer" content="no-referrer">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yanglinqi107.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="决策树算法">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树算法实验">
<meta property="og:url" content="http://yanglinqi107.github.io/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%AE%9E%E9%AA%8C/index.html">
<meta property="og:site_name" content="杨记">
<meta property="og:description" content="决策树算法">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/1_decision_tree.png">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/2_decision_tree.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/3_decision_tree.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/11_decision_tree.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/12_decision_tree.jpg">
<meta property="og:image" content="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/13_decision_tree.jpg">
<meta property="article:published_time" content="2022-07-27T15:30:03.218Z">
<meta property="article:modified_time" content="2022-08-01T12:22:56.620Z">
<meta property="article:author" content="yanglinqi">
<meta property="article:tag" content="数据挖掘">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/1_decision_tree.png">

<link rel="canonical" href="http://yanglinqi107.github.io/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%AE%9E%E9%AA%8C/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>决策树算法实验 | 杨记</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">杨记</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">碎片化学习令人焦虑，系统化学习使人进步</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">22</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">17</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">102</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yanglinqi107.github.io/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%AE%9E%E9%AA%8C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headpic.jpg">
      <meta itemprop="name" content="yanglinqi">
      <meta itemprop="description" content="用于做笔记，对学过的知识总结">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="杨记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          决策树算法实验
        </h1>

        <div class="post-meta">

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-07-27 23:30:03" itemprop="dateCreated datePublished" datetime="2022-07-27T23:30:03+08:00">2022-07-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-01 20:22:56" itemprop="dateModified" datetime="2022-08-01T20:22:56+08:00">2022-08-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>决策树算法</p>
<span id="more"></span>
<h2 id="实验介绍"><a href="#实验介绍" class="headerlink" title="实验介绍"></a>实验介绍</h2><h3 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="1.实验内容"></a>1.实验内容</h3><p>本实验学习并实现决策树算法。</p>
<h3 id="2-实验目标"><a href="#2-实验目标" class="headerlink" title="2.实验目标"></a>2.实验目标</h3><p>通过本实验掌握决策树算法的基本原理。</p>
<h3 id="3-实验知识点"><a href="#3-实验知识点" class="headerlink" title="3.实验知识点"></a>3.实验知识点</h3><ul>
<li>香农熵</li>
<li>信息增益</li>
</ul>
<h3 id="4-实验环境"><a href="#4-实验环境" class="headerlink" title="4.实验环境"></a>4.实验环境</h3><ul>
<li>python 3.6.5</li>
</ul>
<h3 id="5-预备知识"><a href="#5-预备知识" class="headerlink" title="5.预备知识"></a>5.预备知识</h3><ul>
<li>Python编程基础</li>
</ul>
<h2 id="决策树是什么"><a href="#决策树是什么" class="headerlink" title="决策树是什么"></a>决策树是什么</h2><p>　　决策论中，决策树（Decision tree）由一个决策图和可能的结果（包括资源成本和风险）组成， 用来创建到达目标的规划。决策树建立并用来辅助决策，是一种特殊的树结构。决策树是一个利用像树一样的图形或决策模型的决策支持工具，包括随机事件结果，资源代价和实用性。它是一个算法显示的方法。决策树经常在运筹学中使用，特别是在决策分析中，它帮助确定一个能最可能达到目标的策略。如果在实际中，决策不得不在没有完备知识的情况下被在线采用，一个决策树应该平行概率模型作为最佳的选择模型或在线选择模型算法。决策树的另一个使用是作为计算条件概率的描述性手段。<br>　　机器学习中，决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。<br>　　从数据产生决策树的机器学习技术叫做决策树学习,通俗说就是决策树。一个决策树包含三种类型的节点：<br>　　　　1、决策节点：通常用矩形框来表示<br>　　　　2、机会节点：通常用圆圈来表示<br>　　　　3、终结点：通常用三角形来表示<br><img src="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/1_decision_tree.png" alt="img"><br>　　使用决策树做预测需要以下过程：<br>　　　　1、收集数据：可以使用任何方法。比如想构建一个相亲系统，我们可以从媒婆那里，或者通过采访相亲对象获取数据。根据他们考虑的因素和最终的选择结果，就可以得到一些供我们利用的数据了。<br>　　　　2、准备数据：收集完的数据，我们要进行整理，将这些所有收集的信息按照一定规则整理出来，并排版，方便我们进行后续处理。<br>　　　　3、分析数据：可以使用任何方法，决策树构造完成之后，我们可以检查决策树图形是否符合预期。<br>　　　　4、训练算法：这个过程也就是构造决策树，同样也可以说是决策树学习，就是构造一个决策树的数据结构。<br>　　　　5、测试算法：使用经验树计算错误率。当错误率达到了可接收范围，这个决策树就可以投放使用了。<br>　　　　6、使用算法：此步骤可以使用适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。</p>
<h2 id="决策树构建的准备工作"><a href="#决策树构建的准备工作" class="headerlink" title="决策树构建的准备工作"></a>决策树构建的准备工作</h2><p>　　使用决策树做预测的每一步骤都很重要，数据收集不到位，将会导致没有足够的特征让我们构建错误率低的决策树。数据特征充足，但是不知道用哪些特征好，将会导致无法构建出分类效果好的决策树模型。从算法方面看，决策树的构建是我们的核心内容。决策树要如何构建呢？通常，这一过程可以概括为3个步骤：特征选择、决策树的生成和决策树的修剪。<br>　　1、特征选择<br>　　特征选择在于选取对训练数据具有分类能力的特征。这样可以提高决策树学习的效率，如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的。经验上扔掉这样的特征对决策树学习的精度影响不大。通常特征选择的标准是信息增益(information gain)或信息增益比。<br>　　我们选择信息增益作为选择特征的标准，首先来看一组实例，贷款申请样本数据表。<br><img src="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/2_decision_tree.jpg" alt="img">　　希望通过所给的训练数据学习一个贷款申请的决策树，用于对未来的贷款申请进行分类，即当新的客户提出贷款申请时，根据申请人的特征利用决策树决定是否批准贷款申请。特征选择就是决定用哪个特征来划分特征空间。比如，我们通过上述数据表得到两个可能的决策树，分别由两个不同特征的根结点构成。<br><img src="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/3_decision_tree.jpg" alt="img"><br>　　图(a)所示的根结点的特征是年龄，有3个取值，对应于不同的取值有不同的子结点。图(b)所示的根节点的特征是工作，有2个取值，对应于不同的取值有不同的子结点。两个决策树都可以从此延续下去。问题是：究竟选择哪个特征更好些？这就要求确定选择特征的准则。直观上，如果一个特征具有更好的分类能力，或者说，按照这一特征将训练数据集分割成子集，使得各个子集在当前条件下有最好的分类，那么就更应该选择这个特征。信息增益就能够很好地表示这一直观的准则。<br>　　什么是信息增益呢？在划分数据集之后信息发生的变化称为信息增益，知道如何计算信息增益，我们就可以计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。在之后的小节会举例着重说明特征选择。<br>　　2、决策树的生成和修剪<br>　　构建决策树的算法有很多，比如C4.5、ID3和CART，这些算法在运行时并不总是在每次划分数据分组时都会消耗特征。由于特征数目并不是每次划分数据分组时都减少，因此这些算法在实际使用时可能引起一定的问题。目前我们并不需要考虑这个问题，只需要在算法开始运行前计算列的数目，查看算法是否使用了所有属性即可。<br>　　决策树生成算法递归地产生决策树，直到不能继续下去未为止。这样产生的树往往对训练数据的分类很准确，但对未知的测试数据的分类却没有那么准确，即出现过拟合现象。过拟合的原因在于学习时过多地考虑如何提高对训练数据的正确分类，从而构建出过于复杂的决策树。解决这个问题的办法是考虑决策树的复杂度，对已生成的决策树进行简化。</p>
<h2 id="【实验步骤】特征选择—-香浓熵"><a href="#【实验步骤】特征选择—-香浓熵" class="headerlink" title="【实验步骤】特征选择—-香浓熵"></a>【实验步骤】特征选择—-香浓熵</h2><p>　　在可以评测哪个数据划分方式是最好的数据划分之前，我们必须学习如何计算信息增益。集合信息的度量方式称为香农熵或者简称为熵(entropy)，这个名字来源于信息论之父克劳德·香农。熵定义为信息的期望值。在信息论与概率统计中，熵是表示随机变量不确定性的度量。如果待分类的事物可能划分在多个分类中，则符号xi的信息定义为：  </p>
<script type="math/tex; mode=display">\Large l(x_i) = -\log_2p(x_i)</script><p>　　其中p(xi)是选择该分类的概率。<br>　　通过上式，我们可以得到所有类别的信息。为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值(数学期望)，通过下面的公式得到：  </p>
<script type="math/tex; mode=display">\Large H = -\sum_{i=1}^np(x_i)\log_2p(x_i)</script><p>　　其中n是分类的数目。熵越大，随机变量的不确定性就越大。<br>　　当熵中的概率由数据估计(特别是最大似然估计)得到时，所对应的熵称为经验熵。我们定义贷款申请样本数据表中的数据为训练数据集D，则训练数据集D的经验熵为H(D)，|D|表示其样本容量，及样本个数。设有K个类Ck, = 1,2,3,…,K,|Ck|为属于类Ck的样本个数，因此经验熵公式就可以写为：  </p>
<script type="math/tex; mode=display">\Large H(D)=-\sum^K_{k=1}\frac{|C_k|}{|D|}\log_2\frac{|C_k|}{|D|}</script><p>　　根据此公式计算经验熵H(D)，分析上节中贷款申请样本数据表中的数据。最终分类结果只有两类，即放贷和不放贷。根据表中的数据统计可知，在15个数据中，9个数据的结果为放贷，6个数据的结果为不放贷。所以数据集D的经验熵H(D)为：  </p>
<script type="math/tex; mode=display">\Large H(D)=-\frac{9}{15}\log_2\frac{9}{15}-\frac{6}{15}\log_2\frac{6}{15}=0.971</script><p>经过计算可知，数据集D的经验熵H(D)的值为0.971。</p>
<h2 id="【实验步骤】特征选择—-编写代码计算经验熵"><a href="#【实验步骤】特征选择—-编写代码计算经验熵" class="headerlink" title="【实验步骤】特征选择—-编写代码计算经验熵"></a>【实验步骤】特征选择—-编写代码计算经验熵</h2><p>　　在编写代码之前，我们先对数据集进行属性标注。<br>　　　　年龄：0代表青年，1代表中年，2代表老年；<br>　　　　有工作：0代表否，1代表是；<br>　　　　有自己的房子：0代表否，1代表是；<br>　　　　信贷情况：0代表一般，1代表好，2代表非常好；<br>　　　　类别(是否给贷款)：no代表否，yes代表是。<br>　　确定这些之后，我们就可以创建数据集，并计算经验熵了，代码编写如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    无</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">    labels - 分类属性</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span>():</span></span><br><span class="line">    dataSet = [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;no&#x27;</span>],         <span class="comment">#数据集</span></span><br><span class="line">            [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">            [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">            [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">            [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;no&#x27;</span>]]</span><br><span class="line">    labels = [<span class="string">&#x27;不放贷&#x27;</span>, <span class="string">&#x27;放贷&#x27;</span>]             <span class="comment">#分类属性</span></span><br><span class="line">    <span class="keyword">return</span> dataSet, labels                <span class="comment">#返回数据集和分类属性</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">函数说明:计算给定数据集的经验熵(香农熵)</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    shannonEnt - 经验熵(香农熵)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    numEntires = <span class="built_in">len</span>(dataSet)                        <span class="comment">#返回数据集的行数</span></span><br><span class="line">    labelCounts = &#123;&#125;                                <span class="comment">#保存每个标签(Label)出现次数的字典</span></span><br><span class="line">    <span class="comment">#在下面添加代码，对每组特征向量进行统计，得到不同label的计数，并保存到labelCounts中</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> dataSet:</span><br><span class="line">        label = l[<span class="number">4</span>]</span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> labelCounts:</span><br><span class="line">            labelCounts[label] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            labelCounts[label] = labelCounts[label] + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    shannonEnt = <span class="number">0.0</span>                                <span class="comment">#经验熵(香农熵)</span></span><br><span class="line">    <span class="comment">#在下面添加代码，计算当前数据集基于labelCounts的经验熵，结果存放在shannonEnt中</span></span><br><span class="line">    <span class="keyword">for</span> label, count <span class="keyword">in</span> labelCounts.items():</span><br><span class="line">        shannonEnt = shannonEnt - count / numEntires * log(count / numEntires, <span class="number">2</span>)</span><br><span class="line">        <span class="comment">#print(label, count)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> shannonEnt                                <span class="comment">#返回经验熵(香农熵)</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dataSet, features = createDataSet()</span><br><span class="line">    <span class="built_in">print</span>(dataSet)</span><br><span class="line">    <span class="built_in">print</span>(calcShannonEnt(dataSet))</span><br></pre></td></tr></table></figure>
<pre><code>[[0, 0, 0, 0, &#39;no&#39;], [0, 0, 0, 1, &#39;no&#39;], [0, 1, 0, 1, &#39;yes&#39;], [0, 1, 1, 0, &#39;yes&#39;], [0, 0, 0, 0, &#39;no&#39;], [1, 0, 0, 0, &#39;no&#39;], [1, 0, 0, 1, &#39;no&#39;], [1, 1, 1, 1, &#39;yes&#39;], [1, 0, 1, 2, &#39;yes&#39;], [1, 0, 1, 2, &#39;yes&#39;], [2, 0, 1, 2, &#39;yes&#39;], [2, 0, 1, 1, &#39;yes&#39;], [2, 1, 0, 1, &#39;yes&#39;], [2, 1, 0, 2, &#39;yes&#39;], [2, 0, 0, 0, &#39;no&#39;]]
0.9709505944546686
</code></pre><p>程序计算结果数据集经验熵应该为0.9709505944546686，请检查结果是否一致。</p>
<h2 id="【实验步骤】特征选择—-信息增益"><a href="#【实验步骤】特征选择—-信息增益" class="headerlink" title="【实验步骤】特征选择—-信息增益"></a>【实验步骤】特征选择—-信息增益</h2><p>　　信息增益是相对于特征而言的，信息增益越大，特征对最终的分类结果影响也就越大，我们就应该选择对最终分类结果影响最大的那个特征作为我们的分类特征。在讲解信息增益定义之前，我们还需要明确一个概念，条件熵。<br>　　条件熵H(Y|X)表示在已知随机变量X的条件下随机变量Y的不确定性，随机变量X给定的条件下随机变量Y的条件熵(conditional entropy)H(Y|X)，定义为X给定条件下Y的条件概率分布的熵对X的数学期望：  </p>
<script type="math/tex; mode=display">\Large H(Y|X) = \sum^n_{i=1}p_iH(Y|X=x_i)</script><p>同理，当条件熵中的概率由数据估计(特别是极大似然估计)得到时，所对应的条件熵称为条件经验熵。<br>　　信息增益是相对于特征而言的。所以，特征A对训练数据集D的信息增益g(D,A)，定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差，即：  </p>
<script type="math/tex; mode=display">\Large g(D,A)=H(D)-H(D|A)</script><p>　　设特征A有n个不同的取值{a1,a2,···,an}，根据特征A的取值将D划分为n个子集{D1,D2，···,Dn}，|Di|为Di的样本个数。记子集Di中属于Ck的样本的集合为Dik，即Dik = Di ∩ Ck，|Dik|为Dik的样本个数。于是经验条件熵的公式可以写为：  </p>
<script type="math/tex; mode=display">\Large H(D|A)=\sum_{i=1}^n\frac{|D_i|}{|D|}H(D_i)=-\sum_{i=1}^n\frac{|D_i|}{|D|}\sum^K_{k=1}\frac{|C_{ik}|}{|D_i|}\log_2\frac{|C_{ik}|}{|D_i|}</script><p>　　以贷款申请样本数据表为例进行说明。看下年龄这一列的数据，也就是特征A1，一共有三个类别，分别是：青年、中年和老年。我们只看年龄是青年的数据，年龄是青年的数据一共有5个，所以年龄是青年的数据在训练数据集出现的概率是十五分之五，也就是三分之一。同理，年龄是中年和老年的数据在训练数据集出现的概率也都是三分之一。现在我们只看年龄是青年的数据的最终得到贷款的概率为五分之二，因为在五个数据中，只有两个数据显示拿到了最终的贷款，同理，年龄是中年和老年的数据最终得到贷款的概率分别为五分之三、五分之四。所以计算年龄的信息增益，过程如下：  </p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/11_decision_tree.jpg" alt=""></p>
<p>　　同理，计算其余特征的信息增益g(D,A2)、g(D,A3)和g(D,A4)。分别为：  </p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/12_decision_tree.jpg" alt=""></p>
<p><img src="https://gitee.com/yanglinqi107/Images/raw/master/DataMining-img/13_decision_tree.jpg" alt=""></p>
<p>　　最后，比较特征的信息增益，由于特征A3(有自己的房子)的信息增益值最大，所以选择A3作为最优特征。</p>
<h2 id="【实验步骤】特征选择—-编写代码计算信息增益"><a href="#【实验步骤】特征选择—-编写代码计算信息增益" class="headerlink" title="【实验步骤】特征选择—-编写代码计算信息增益"></a>【实验步骤】特征选择—-编写代码计算信息增益</h2><p>我们已经学会了通过公式计算信息增益，接下来编写代码，计算信息增益。splitDataSet函数是用来选择各个特征的子集的，比如选择年龄(第0个特征)的青年(用0代表)的自己，我们可以调用splitDataSet(dataSet,0,0)这样返回的子集就是年龄为青年的5个数据集。chooseBestFeatureToSplit是选择选择最优特征的函数。运行代码结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">函数说明:按照给定特征划分数据集，得到第axis维特征值为value的划分数据子集</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 待划分的数据集</span></span><br><span class="line"><span class="string">    axis - 划分数据集的特征</span></span><br><span class="line"><span class="string">    value - 需要返回的特征的值</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    无</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span>(<span class="params">dataSet, axis, value</span>):</span>       </span><br><span class="line">    retDataSet = []             <span class="comment">#创建返回的数据集列表</span></span><br><span class="line">    <span class="comment">#在下面添加代码，将dataSet中第axis维特征等于value的数据取出，存放入retDataSet</span></span><br><span class="line">    <span class="comment">#注意，为方便后面的计算，存放入retDataSet的每一组记录需要去掉axis特征</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> dataSet:</span><br><span class="line">        tmp = []</span><br><span class="line">        <span class="keyword">if</span> data[axis] == value:</span><br><span class="line">            retDataSet.append(data)</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> retDataSet     <span class="comment">#返回划分后的数据集</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">函数说明:选择最优特征</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    bestFeature - 信息增益最大的(最优)特征的索引值</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    numEntires = <span class="built_in">len</span>(dataSet)                           <span class="comment"># 数据集的行数</span></span><br><span class="line">    numFeatures = <span class="built_in">len</span>(dataSet[<span class="number">0</span>]) - <span class="number">1</span>                    <span class="comment">#特征数量</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)                 <span class="comment">#计算数据集的香农熵</span></span><br><span class="line">    bestInfoGain = <span class="number">0.0</span>                                  <span class="comment">#信息增益</span></span><br><span class="line">    bestFeature = -<span class="number">1</span>                                    <span class="comment">#最优特征的索引值</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numFeatures):                         <span class="comment">#遍历所有特征</span></span><br><span class="line">        <span class="comment">#获取dataSet的第i个所有特征</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        uniqueVals = <span class="built_in">set</span>(featList)                         <span class="comment">#创建set集合&#123;&#125;,元素不可重复</span></span><br><span class="line">        newEntropy = <span class="number">0.0</span>                                  <span class="comment">#经验条件熵</span></span><br><span class="line">        <span class="comment">#在下方添加代码，计算根据uniqueVals中的特征值划分的数据子集的条件熵，for循环中需要调用splitDataSet函数，结果记录到newEntropy中</span></span><br><span class="line">        yes = <span class="number">0</span></span><br><span class="line">        no = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> val <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, val)</span><br><span class="line">            subLen = <span class="built_in">len</span>(subDataSet)  <span class="comment"># 数据子集长度</span></span><br><span class="line">            <span class="keyword">for</span> subData <span class="keyword">in</span> subDataSet:</span><br><span class="line">                <span class="keyword">if</span> subData[-<span class="number">1</span>] == <span class="string">&quot;yes&quot;</span>:</span><br><span class="line">                    yes = yes + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    no = no + <span class="number">1</span></span><br><span class="line">        newEntropy -= subLen / numEntires * (yes / subLen * log(yes / subLen, <span class="number">2</span>) + no / subLen * log(no / subLen, <span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">        infoGain = baseEntropy - newEntropy                     <span class="comment">#信息增益</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;第%d个特征的增益为%.3f&quot;</span> % (i, infoGain))            <span class="comment">#打印每个特征的信息增益</span></span><br><span class="line">        <span class="keyword">if</span> (infoGain &gt; bestInfoGain):                             <span class="comment">#计算信息增益</span></span><br><span class="line">            bestInfoGain = infoGain                             <span class="comment">#更新信息增益，找到最大的信息增益</span></span><br><span class="line">            bestFeature = i                                     <span class="comment">#记录信息增益最大的特征的索引值</span></span><br><span class="line">    <span class="keyword">return</span> bestFeature                                             <span class="comment">#返回信息增益最大的特征的索引值</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dataSet, features = createDataSet()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最优特征索引值:&quot;</span> + <span class="built_in">str</span>(chooseBestFeatureToSplit(dataSet)))</span><br></pre></td></tr></table></figure>
<pre><code>第0个特征的增益为1.585
第1个特征的增益为1.585
第2个特征的增益为1.322
第3个特征的增益为1.907
最优特征索引值:3
</code></pre><p>最优特征的索引值为2，也就是特征A3(有自己的房子)，请检查结果是否一致。</p>
<h2 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h2><p>通过本次实验，掌握并实现决策树算法的基本原理。</p>

    </div>

    
    
    
        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      
      
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">实验介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9"><span class="nav-number">1.1.</span> <span class="nav-text">1.实验内容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%AE%9E%E9%AA%8C%E7%9B%AE%E6%A0%87"><span class="nav-number">1.2.</span> <span class="nav-text">2.实验目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E5%AE%9E%E9%AA%8C%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="nav-number">1.3.</span> <span class="nav-text">3.实验知识点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="nav-number">1.4.</span> <span class="nav-text">4.实验环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86"><span class="nav-number">1.5.</span> <span class="nav-text">5.预备知识</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">2.</span> <span class="nav-text">决策树是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%9E%84%E5%BB%BA%E7%9A%84%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="nav-number">3.</span> <span class="nav-text">决策树构建的准备工作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E3%80%90%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4%E3%80%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E2%80%94-%E9%A6%99%E6%B5%93%E7%86%B5"><span class="nav-number">4.</span> <span class="nav-text">【实验步骤】特征选择—-香浓熵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E3%80%90%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4%E3%80%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E2%80%94-%E7%BC%96%E5%86%99%E4%BB%A3%E7%A0%81%E8%AE%A1%E7%AE%97%E7%BB%8F%E9%AA%8C%E7%86%B5"><span class="nav-number">5.</span> <span class="nav-text">【实验步骤】特征选择—-编写代码计算经验熵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E3%80%90%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4%E3%80%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E2%80%94-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A"><span class="nav-number">6.</span> <span class="nav-text">【实验步骤】特征选择—-信息增益</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E3%80%90%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4%E3%80%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E2%80%94-%E7%BC%96%E5%86%99%E4%BB%A3%E7%A0%81%E8%AE%A1%E7%AE%97%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A"><span class="nav-number">7.</span> <span class="nav-text">【实验步骤】特征选择—-编写代码计算信息增益</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93"><span class="nav-number">8.</span> <span class="nav-text">实验总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="yanglinqi"
      src="/images/headpic.jpg">
  <p class="site-author-name" itemprop="name">yanglinqi</p>
  <div class="site-description" itemprop="description">用于做笔记，对学过的知识总结</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">102</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yanglinqi107" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yanglinqi107" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yanglinqi</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.1.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


  <script async src="/js/cursor/fireworks.js"></script>


</body>
</html>
